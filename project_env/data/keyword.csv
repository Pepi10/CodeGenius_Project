,keyword1,keyword2,keyword3,keyword4,keyword5,code,code_copy,code_result,doc_url
0,변수,타입,type,,,type(변수),"text = ""안녕하세요""
type(text)",str,https://docs.python.org/ko/3/library/functions.html#type
1,리스트,특정요소,삭제,remove,특정 요소,리스트.remove(요소),"fruits = [""apple"", ""banana"", ""cherry""]
fruits.remove(""banana"")
print(fruits)","['apple', 'cherry']",https://docs.python.org/ko/3/tutorial/datastructures.html#more-on-lists
2,해쉬셋,remove,제거,값,세트,셋.remove(값),"fruits = {""apple"", ""banana"", ""cherry""}
fruits.remove(""banana"")
print(fruits)","{""apple"", ""cherry""}",https://docs.python.org/ko/3/library/stdtypes.html#frozenset.remove
3,문자열,변환,대문자,소문자,메서드,문자열.upper(),"text = ""apple""
up_text = str.upper()
print(up_text)",APPLE,https://docs.python.org/ko/3/library/stdtypes.html#str.upper
4,딕셔너리,값,검색,키워드,사전,딕셔너리[키],"dic = {""fruit"": ""apple"", ""food"": ""pie""}
fruit_value = dic[""fruit""]
print(fruit_value)",apple,https://docs.python.org/ko/3/tutorial/datastructures.html#dictionaries
5,숫자,문자열,변환,str,,str(숫자),"number = 99
str_number = str(number)
print(str_number)",99,https://docs.python.org/ko/3/library/stdtypes.html#str
6,for,모든요소,리스트,작업,모든 요소,for 요소 in 리스트:,"fruits = [""apple"", ""banana"", ""cherry""]
for fruit in fruits:
    print(fruit)","apple
banana
cherry",https://docs.python.org/ko/3/tutorial/controlflow.html#for-statements
7,조건,if,else,elif,,"if 조건:
   # 코드
elif 조건:
   # 코드
else:
   # 코드","score = 85
if score >= 90:
    print(""A"")
elif score >= 80:
    print(""B"")
else:
    print(""C"")",B,https://docs.python.org/ko/3/tutorial/controlflow.html#if-statements
8,함수,정의,def,,,"def 함수_이름(인수):
   # 함수 정의","# 함수 정의
def add_number(a, b):
    result = a+b
    return result

# 함수 호출
sum_result = add_number(5, 3)
print(sum_result)",8,https://docs.python.org/ko/3/tutorial/controlflow.html#defining-functions
9,리스트,요소,추가,append,,리스트.append(요소),"fruits = [""apple"", ""banana"", ""cherry""]
fruits.append(""orange"")
print(fruits)","[""apple"", ""banana"", ""cherry"", ""orange""]",https://docs.python.org/ko/3/tutorial/datastructures.html
10,클래스,정의,class,메서드,지정,"class Myclass:
    def __init__(self, name):
        self.name = name","# 클래스 정의
class MyClass:
    def __init__(self, name, age):
        self.name = name
        self.age = age

    def display_age(self):
        print(f""{self.name} is {self.age} years old."")

# 객체 생성
person = MyClass(""Bob"", 30)

# 메서드 호출
person.display_age()",Bob is 30 years old.,https://docs.python.org/ko/3/tutorial/classes.html
11,파일,읽기,열기,open,read,"with open(파일명, ""r"") as file:
    content = file.read()","# 파일 읽기: example.txt 파일이 있다고 가정, 없는 경우 에러 발생
with open(""example.txt"", ""r"") as file:
    content = file.read()

# 파일 내용 출력
print(content)",,https://docs.python.org/ko/3/tutorial/inputoutput.html#reading-and-writing-files
12,모듈,import,지정,이름,가져,import pandas,import pandas as pd,,https://docs.python.org/ko/3/tutorial/modules.html
13,예외처리,try,except,예외 처리,발생,"try:
    # 예외가 발생할 수 있는 코드
except Exception as e:
    # 예외 처리 코드","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]
try:
    print(fruits[5])
except IndexError as e:
    print(""Error: Index out of range."")",Error: Index out of range.,https://docs.python.org/ko/3/tutorial/errors.html
14,리스트,딕셔너리,변환,dict,사전,"dict(zip(키 리스트, 값 리스트))","# 키 리스트와 값 리스트 정의
keys = [""name"", ""age"", ""city""]
values = [""Alice"", 25, ""New York""]

# dict와 zip을 사용하여 딕셔너리 생성
result_dict = dict(zip(keys, values))

# 결과 출력
print(result_dict)","{'name': 'Alice', 'age': 25, 'city': 'New York'}",https://docs.python.org/ko/3/library/functions.html#func-dict
15,문자열,공백제거,strip,공백 제거,메서드,문자열.strip(),"text = ""  안녕하세요   ""
strip_text = str.strip()
print(strip_text)",안녕하세요,https://docs.python.org/ko/3/library/stdtypes.html#str.strip
16,enumerate,인덱스,요소,리스트,반환,"for 인덱스, 요소 in enumerate(리스트):","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

# enumerate를 사용하여 리스트의 인덱스와 요소를 반복
for index, fruit in enumerate(fruits):
    print(index, fruit)","0 apple
1 banana
2 cherry",https://docs.python.org/ko/3/library/functions.html#enumerate
17,튜플,길이,len,함수,,len(튜플),"fruits = (""apple"", ""banana"", ""cherry"")
len(fruits)",3,https://docs.python.org/ko/3/library/stdtypes.html#common-sequence-operations
18,리스트,길이,len,함수,,len(리스트),"fruits = [""apple"", ""banana"", ""cherry""]
len(fruits)",3,https://docs.python.org/ko/3/library/stdtypes.html#common-sequence-operations
19,셋,길이,len,함수,해쉬,len(셋),"fruits = {""apple"", ""banana"", ""cherry""}
len(fruits)",3,https://docs.python.org/ko/3/library/stdtypes.html#common-sequence-operations
20,문자열,위치,find,첫,문자,문자열.find(문자),"text = ""Hello I'm CodeGenius""
text.find(""m"")",8,https://docs.python.org/ko/3/library/stdtypes.html#str.find
21,리스트,정렬,sort,메서드,,리스트.sort(),"fruits = [""banana"", ""cherry"", ""apple""]
fruits.sort()
print(fruits)","['apple', 'banana', 'cherry']",https://docs.python.org/ko/3/library/stdtypes.html#list.sort
22,집합,set,생성,,,"set([값1, 값2, ...])","fruits = [""banana"", ""cherry"", ""apple""]
set(fruits)","{'apple', 'banana', 'cherry'}",https://docs.python.org/ko/3/tutorial/datastructures.html#sets
23,리스트,sum,합계,원소,,"sum([1, 2, 3])","numbers = [1, 2, 3, 4, 5]
sum(numbers)",15,https://docs.python.org/ko/3/library/functions.html#sum
24,딕셔너리,키 목록,반환,keys,키목록,딕셔너리.keys(),"dic = {""fruit"": ""apple"", ""food"": ""pie""}
dic.keys()","dict_keys(['fruit', 'food'])",https://docs.python.org/ko/3/library/stdtypes.html#dict.keys
25,input,사용자입력,함수,사용자 입력,입력,input(),"input(""입력하세요: "")",,https://docs.python.org/ko/3/library/functions.html#input
26,break,코드,조기종료,조기 종료,,"for i in range(10):
    if i == 5:
        break","for num in range(10):
    print(num)
    if num == 5:
        break","0
1
2
3
4
5",https://docs.python.org/ko/3/reference/compound_stmts.html#else-clause
27,비교연산,불리언,관계,비교 연산,평가,"if x == y:
    print(""x와 y는 같음"")","x = [1,2,3]
y = [1,2,3]
if x == y:
    print(""x와 y는 같음"")",x와 y는 같음,https://docs.python.org/ko/3/library/stdtypes.html#comparisons
28,정수,변환,int,문자열,,int(숫자로 이루어진 문자열),"number = ""99""
int(number)",99,https://docs.python.org/ko/3/library/functions.html#int
29,range,범위,순회,정수,함수,"range(시작, 종료, 간격)","for i in range(1, 10, 2):
    print(i)","1
3
5
7
9",https://docs.python.org/ko/3/library/stdtypes.html#range
30,반복문,요소,출력,리스트,for,for 요소 in 리스트:,"fruits = [""apple"", ""banana"", ""cherry""]
for fruit in fruits:
    print(fruit)","apple
banana
cherry",https://docs.python.org/ko/3/tutorial/controlflow.html#for-statements
31,정규표현식,패턴,compile,생성,정규 표현식,re.compile(패턴),"import re

# 정규 표현식 패턴 컴파일
pattern = re.compile(r'\d+')  # 하나 이상의 숫자에 매칭되는 패턴

# 테스트할 문자열
text = ""제 전화번호는 010-1234-5678입니다.""

# 패턴을 사용하여 문자열 검색
matches = pattern.findall(text)

# 결과 출력
print(matches)","['010', '1234', '5678']",https://docs.python.org/ko/3/library/re.html#re.compile
32,set,원소,추가,add,세트,셋.add(원소),"fruits = {""apple"", ""banana"", ""cherry""}
fruits.add(""orange"")
print(fruits)  # 결과는 순서없이 무작위로 나열됨","{'banana', 'apple', 'cherry', 'orange'}",https://docs.python.org/ko/3/library/stdtypes.html#frozenset.add
33,논리연산,and,or,not,논리 연산,"변수1 and 변수2
변수1 or 변수2
not 변수","# 변수 정의
T = True
F = False

print(T and F)
print(T or F)
print(not F)","False
True
True",https://docs.python.org/ko/3/library/stdtypes.html#boolean-operations-and-or-not
34,람다,식,반환,값,lambda,lambda x: x + 1,"# lambda 함수 정의
add1 = lambda x: x + 1
add1(5)",6,https://docs.python.org/ko/3/tutorial/controlflow.html#lambda-expressions
35,딕셔너리,생성,{},콜론,사전,"{'이름': '홍길동', '나이': 20}","dic = {'이름': '홍길동', '나이': 20}
print(dic)","{'이름': '홍길동', '나이': 20}",https://docs.python.org/ko/3/library/stdtypes.html#dict
36,문자열,구분,split,메서드,,문자열.split(),"text = ""안녕하세요, 저는 파이썬 교육 챗봇입니다.""
text.split()","['안녕하세요,', '저는', '파이썬', '교육', '챗봇입니다.']",https://docs.python.org/ko/3/library/stdtypes.html#str.split
37,리스트,요소,함수적용,map,함수 적용,"map(함수, 리스트)","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

# map 함수를 사용하여 각 요소에 len 함수를 적용
result = map(len, fruits)

# 결과를 리스트로 변환하여 출력
print(list(result))
","[5, 6, 6]",https://docs.python.org/ko/3/library/functions.html#map
38,setdefault,딕셔너리,추가,사전,키,"딕셔너리.setdefault(키, 값)","# 딕셔너리 정의
my_dict = {'name': 'Alice', 'age': 25}

# setdefault 메서드 사용
my_dict.setdefault('city', 'New York')

print(my_dict)
","{'name': 'Alice', 'age': 25, 'city': 'New York'}",https://docs.python.org/ko/3/library/stdtypes.html#dict.setdefault
39,리스트,튜플,변환,tuple,함수,tuple(['리스트']),"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

tuple(fruits)","('apple', 'banana', 'cherry')",https://docs.python.org/ko/3/library/functions.html#func-tuple
40,딕셔너리,sorted,정렬,키워드,함수,sorted(딕셔너리.keys()),"# 딕셔너리 정의
my_dict = {'name': 'Alice', 'age': 25}

sorted(my_dict.keys())","['age', 'name']",https://docs.python.org/ko/3/library/functions.html#sorted
41,숫자,반올림,round,함수,,"round(숫자, 소수점 자리 수)","round(3.141592, 3)",3.142,https://docs.python.org/ko/3/library/functions.html#round
42,리스트,역순,정렬,reverse,sort,리스트.sort(reverse=True),"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

fruits.sort(reverse=True)

print(fruits)","['cherry', 'banana', 'apple']",https://docs.python.org/ko/3/library/stdtypes.html#list.sort
43,딕셔너리,값,get,메서드,찾,딕셔너리.get(키),"# 딕셔너리 정의
my_dict = {'name': 'Alice', 'age': 25}

my_dict.get('age')",25,https://docs.python.org/ko/3/library/stdtypes.html#dict.get
44,복소수,리터럴,실수,허수,j,2 + 3j,"# 복소수 정의
complex_number = 2 + 3j

print(""복소수:"", complex_number)
print(""실수 부분:"", complex_number.real)
print(""허수 부분:"", complex_number.imag)","복소수: (2+3j)
실수 부분: 2.0
허수 부분: 3.0",https://docs.python.org/ko/3/reference/lexical_analysis.html#numeric-literals
45,인덱싱,대괄호,index,[],데이터,numbers[0] # 첫 번째 요소에 접근,"fruits = [""apple"", ""banana"", ""cherry""]
print(fruits[0])",apple,https://docs.python.org/ko/3/tutorial/introduction.html#lists
46,문자열,splitlines,줄,여러,함수,문자열.splitlines(),"# 여러 줄로 구성된 문자열 정의
multiline_text = ""안녕하세요\n저는 코드지니어스입니다\n파이썬 관련 질문을 해주세요!""

multiline_text.splitlines()","['안녕하세요', '저는 코드지니어스입니다', '파이썬 관련 질문을 해주세요!']",https://docs.python.org/ko/3/library/stdtypes.html#str.splitlines
47,문자열,역순,표시,reversed,함수,reversed(문자열),"text = ""저는 코드지니어스입니다.""

reversed_text_list = list(reversed(text))
print(reversed_text_list)","['.', '다', '니', '입', '스', '어', '니', '지', '드', '코', ' ', '는', '저']",https://docs.python.org/ko/3/library/functions.html#reversed
48,문자열,소문자,변경,lower,메서드,문자열.lower(),"text = ""APPLE""
lower_text = text.lower()
print(lower_text)",apple,https://docs.python.org/ko/3/library/stdtypes.html#str.lower
49,나머지,%,연산자,두숫자,두 숫자,숫자1 % 숫자2,print(10 % 3),1,https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex
50,몫,//,연산자,두숫자,두 숫자,숫자1 // 숫자2,print(10 // 3),3,https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex
51,합,+,연산자,두숫자,두 숫자,숫자1 + 숫자2,print(10 + 3),13,https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex
52,차,-,연산자,두숫자,두 숫자,숫자1 - 숫자2,print(10 - 3),7,https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex
53,곱,*,연산자,두숫자,두 숫자,숫자1 * 숫자2,print(10 * 3),30,https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex
54,abs,절대값,숫자,크기,,abs(숫자),abs(-11),11,https://docs.python.org/ko/3/library/stdtypes.html#numeric-types-int-float-complex
55,join,문자열,결합,리스트,함수,""""".join([문자1, 문자2])","text_list = [""안녕하세요"", ""코드지니어스입니다""]
joined_text = """".join(text_list)
print(joined_text)",안녕하세요코드지니어스입니다,https://docs.python.org/ko/3/library/stdtypes.html#str.join
56,특정패턴,검사,문자열,search,특정 패턴,"re.search(패턴, 문자열)","import re

# 패턴과 검색할 문자열 정의
pattern = ""코드""
text = ""안녕하세요 저는 코드지니어스입니다""

# re.search()를 사용하여 패턴 검색
re.search(pattern, text)","<re.Match object; span=(9, 11), match='코드'>",https://docs.python.org/ko/3/library/re.html#re.search
57,특정문자,replace,메서드,특정 문자,바꾸,"문자열.replace(""원본문자"", ""바꿀문자"")","text = ""코드지니오스입니다.""
replaced_text = text.replace(""오"", ""어"")
print(replaced_text)",코드지니어스입니다.,https://docs.python.org/ko/3/library/stdtypes.html#str.replace
58,전역변수,global,함수,전역 변수,접근,global 변수명,"# 전역 변수 선언
count = 0

def global_count():
    global count  # 전역 변수 사용
    count += 1
    print(count)

# 함수 호출
global_count()
global_count()","1
2",https://docs.python.org/ko/3/reference/simple_stmts.html#the-global-statement
59,도움말,내장함수,help,내장 함수,,help(함수명),help(sum),"Help on built-in function sum in module builtins:

sum(iterable, /, start=0)
    Return the sum of a 'start' value (default: 0) plus an iterable of numbers
    
    When the iterable is empty, return the start value.
    This function is intended specifically for use with numeric values and may
    reject non-numeric types.",https://docs.python.org/ko/3/library/functions.html#help
60,정규표현식,문자열,검색,re,정규 표현식,"re.search(패턴, 문자열)","import re

# 패턴과 검색할 문자열 정의
pattern = ""코드""
text = ""안녕하세요 저는 코드지니어스입니다""

# re.search()를 사용하여 패턴 검색
re.search(pattern, text)","<re.Match object; span=(9, 11), match='코드'>",https://docs.python.org/ko/3/library/re.html#re.search
61,디렉토리,생성,mkdir,os,함수,os.mkdir(디렉토리 경로),"import os

# 새로 생성할 디렉토리 경로 정의
directory_path = ""new_directory""

# 디렉토리 생성: 이미 존재하는 경우 에러 발생
os.mkdir(directory_path)",,https://docs.python.org/ko/3/library/os.html#os.mkdir
62,thread,생성,threading,모듈,,threading.Thread(target=함수 이름),"import threading
import time

# 스레드에서 실행할 간단한 함수 정의
def print_numbers():
    for i in range(5):
        print(f""Thread: {i}"")
        time.sleep(1)

# 스레드 생성
thread = threading.Thread(target=print_numbers)

# 스레드 시작
thread.start()

# 메인 스레드에서 실행할 작업
for i in range(5):
    print(f""Main: {i}"")
    time.sleep(1)

# 스레드가 종료될 때까지 기다림
thread.join()

print(""스레드가 종료되었습니다."")","import threading
import time

# 스레드에서 실행할 간단한 함수 정의
def print_numbers():
    for i in range(5):
        print(f""Thread: {i}"")
        time.sleep(1)

# 스레드 생성
thread = threading.Thread(target=print_numbers)

# 스레드 시작
thread.start()

# 메인 스레드에서 실행할 작업
for i in range(5):
    print(f""Main: {i}"")
    time.sleep(1)

# 스레드가 종료될 때까지 기다림
thread.join()

print(""스레드가 종료되었습니다."")
",https://docs.python.org/ko/3/library/threading.html#threading.Thread
63,match,정규식,문자열,일치,함수,"re.match(정규식, 문자열)","import re

# 패턴과 검색할 문자열 정의
pattern = ""코드""
text = ""안녕하세요 저는 코드지니어스입니다.""

# 문자열의 시작이 패턴과 일치하는지 확인
re.match(pattern, text)",,https://docs.python.org/ko/3/library/re.html#re.match
64,교집합,&,세트,집합,연산자,집합1 & 집합2,"# 두 집합 정의
fruits1 = {""apple"", ""banana"", ""cherry""}
fruits2 = {""orange"", ""melon"", ""banana""}

print(fruits1 & fruits2)",{'banana'},https://docs.python.org/ko/3/library/stdtypes.html#frozenset.intersection
65,is,확인,객체,연산자,같,객체1 is 객체2,"# 두 객체 정의
fruits1 = [""apple"", ""banana"", ""cherry""]
fruits2 = [""apple"", ""banana"", ""cherry""]

fruits1 is fruits2",False,https://docs.python.org/ko/3/reference/expressions.html#is
66,in,시퀀스,요소,연산자,포함,요소 in 시퀀스,"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

# 요소가 리스트에 있는지 확인
print(""orange"" in fruits)",False,https://docs.python.org/ko/3/library/stdtypes.html#common-sequence-operations
67,리스트,항목삭제,clear,모든,항목 삭제,리스트.clear(),"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

fruits.clear()
print(fruits)",[],https://docs.python.org/ko/3/tutorial/datastructures.html#data-structures
68,변수,삭제,del,키워드,,del 변수명,"fruits = [""apple"", ""banana"", ""cherry""]
del fruits[0]
print(fruits)","['banana', 'cherry']",https://docs.python.org/ko/3/tutorial/datastructures.html#the-del-statement
69,리스트,인덱스,요소,index,함수,리스트.index(요소),"fruits = [""apple"", ""banana"", ""cherry""]
fruits.index('banana')",1,https://docs.python.org/ko/3/tutorial/datastructures.html#list-objects
70,정규표현식,대소문자,무시,IGNORECASE,플래그,"re.compile(패턴, re.IGNORECASE)","import re

# 정규 표현식 패턴 컴파일 (대소문자 구분 없음)
pattern = re.compile('codegenius', re.IGNORECASE)

# 테스트할 문자열
text = ""my name is CodeGenius ChatBot.""

# 패턴을 사용하여 문자열 검색
matches = pattern.findall(text)

# 결과 출력
print(matches)",['CodeGenius'],https://docs.python.org/ko/3/library/re.html#re.IGNORECASE
71,정규표현식,일치,패턴,DOTALL,플래그,"re.compile(패턴, re.DOTALL)","import re

# 정규 표현식 패턴 컴파일 (모든 문자와 줄 바꿈 포함)
pattern = re.compile('안녕.*코드', re.DOTALL)

# 테스트할 문자열
text = ""안녕하세요, \n저는 코드지니어스입니다.""

# 패턴을 사용하여 문자열 검색
matches = pattern.findall(text)

# 결과 출력
print(matches)","['안녕하세요, \n저는 코드']",https://docs.python.org/ko/3/library/re.html#re.DOTALL
72,정규표현식,대체,문자열,sub,바꾸,"re.sub(패턴, 대체, 문자열)","import re

pattern = ""코드""
text = ""저는 당신의지니어스입니다.""

sub_text = re.sub(""당신의"", pattern, text)
print(sub_text)",저는 코드지니어스입니다.,https://docs.python.org/ko/3/library/re.html#re.sub
73,정규표현식,패턴,findall,문자열,찾,"re.findall(패턴, 문자열)","import re

pattern = ""코드""
text = ""저는 코드지니어스입니다.""

re.findall(pattern, text)",['코드'],https://docs.python.org/ko/3/library/re.html#re.findall
74,튜플,요소선택,choice,random,요소 선택,random.choice(튜플),"import random

# 튜플 정의
fruits = ('apple', 'banana', 'cherry')

# 튜플에서 임의의 요소 선택
random_fruits = random.choice(fruits)

print(random_fruits) # 결과는 실행할 때마다 달라짐",apple,https://docs.python.org/ko/3/library/random.html#random.choice
75,객체,튜플,isinstance,함수,확인,"isinstance(객체, tuple)","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

isinstance(fruits, tuple)",False,https://docs.python.org/ko/3/library/functions.html#isinstance
76,객체,딕셔너리,isinstance,함수,확인,"isinstance(객체, dict)","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

isinstance(fruits, dict)",False,https://docs.python.org/ko/3/library/functions.html#isinstance
77,객체,리스트,isinstance,함수,확인,"isinstance(객체, list)","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

isinstance(fruits, list)",True,https://docs.python.org/ko/3/library/functions.html#isinstance
78,순환객체,요소,all,함수,확인,all(순환객체),"# 리스트 정의
fruits1 = [""apple"", ""banana"", ""cherry""]
fruits2 = [""apple"", ""banana"", ""cherry"", """"]

print(all(fruits1))
print(all(fruits2))","True
False",https://docs.python.org/ko/3/library/functions.html#all
79,리스트,복사,copy,메서드,생성,리스트.copy(),"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

# 리스트 복사
copy_fruits = fruits.copy()

print(copy_fruits)","['apple', 'banana', 'cherry']",https://docs.python.org/ko/3/tutorial/datastructures.html
80,리스트,삽입,insert,원소,인덱스,"리스트.insert(인덱스, 원소)","# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

fruits.insert(1, ""orange"") # 인덱스가 1인 자리에 orange 추가

print(fruits)","['apple', 'orange', 'banana', 'cherry']",https://docs.python.org/ko/3/tutorial/datastructures.html
81,리스트,값,count,카운트,메서드,리스트.count(값),"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry"", ""banana"", ""orange"", ""melon""]

fruits.count(""banana"")",2,https://docs.python.org/ko/3/tutorial/datastructures.html
82,리스트,삭제,pop,원소,메서드,리스트.pop(인덱스),"# 리스트 정의
fruits = [""apple"", ""banana"", ""cherry""]

print(fruits.pop(1))",banana,https://docs.python.org/ko/3/tutorial/datastructures.html#more-on-lists
83,리스트,합,extend,메서드,두,리스트1.extend(리스트2),"# 리스트 정의
fruits1 = [""apple"", ""banana"", ""cherry""]
fruits2 = [""melon"", ""orange""]

# fruits1에 fruits2요소 추가
fruits1.extend(fruits2)

print(fruits1)","['apple', 'banana', 'cherry', 'melon', 'orange']",https://docs.python.org/ko/3/tutorial/datastructures.html
84,키와 값,반환,items,변수,할당,"for 키, 값 in 딕셔너리.items():","# 딕셔너리 정의
dic = {""fruit"": ""apple"", ""food"": ""pie""}

# 반복문을 돌며 key와 value 출력
for key, val in dic.items():
    print(key, val)","fruit apple
food pie",https://docs.python.org/ko/3/tutorial/datastructures.html
85,딕셔너리,병합,update,메서드,,딕셔너리1.update(딕셔너리2),"# 딕셔너리 정의
dic1 = {""fruit"": ""apple"", ""food"": ""pie""}
dic2 = {""fruit"": ""banana"", ""idx"": 1}

# dic1에 dic2 병합: 중복된 키는 값 변경됨
dic1.update(dic2)

print(dic1)","{'fruit': 'banana', 'food': 'pie', 'idx': 1}",https://docs.python.org/ko/3/library/stdtypes.html#dict.update
86,딕셔너리,값,values,메서드,모든,딕셔너리.values(),"# 딕셔너리 정의
dic = {""fruit"": ""apple"", ""food"": ""pie""}

dic.values()","dict_values(['apple', 'pie'])",https://docs.python.org/ko/3/library/stdtypes.html#dict.values
87,딕셔너리,Counter,collections,클래스,찾,"import collections

collections.Counter(딕셔너리)","import collections

# 딕셔너리 정의
dic = {""fruit"": ""apple"", ""food"": ""pie""}

# 딕셔너리를 Counter 객체로 변환
counter = collections.Counter(dic)

# 결과 출력
print(counter)","Counter({'food': 'pie', 'fruit': 'apple'})",https://docs.python.org/ko/3/library/collections.html#collections.Counter
88,딕셔너리,순서,OrderdDict,지정,클래스,"import collections

collections.OrderedDict(딕셔너리)","import collections

# 딕셔너리 정의
dic = {""fruit"": ""apple"", ""food"": ""pie""}

# OrderedDict로 변환
ordered_dict = collections.OrderedDict(dic)

# 결과 출력
print(""OrderedDict:"", ordered_dict)","OrderedDict: OrderedDict([('fruit', 'apple'), ('food', 'pie')])",https://docs.python.org/ko/3/library/collections.html#collections.OrderedDict
89,딕셔너리,데이터 유형,변환,모듈,데이터유형,"import json

json.dumps(딕셔너리)","import json

# 딕셔너리 정의
dic = {""fruit"": ""apple"", ""food"": ""pie""}

# 딕셔너리를 JSON 문자열로 변환
json_string = json.dumps(dic)

# 결과 출력
print(json_string)","{""fruit"": ""apple"", ""food"": ""pie""}",https://docs.python.org/ko/3/library/json.html
90,셋,합집합,union,합,해쉬,셋1.union(셋2),"# 두 해쉬셋 정의
fruits1 = {""apple"", ""banana"", ""cherry""}
fruits2 = {""orange"", ""melon"", ""banana""}

# 합집합 출력
print(fruits1.union(fruits2))","{'apple', 'banana', 'cherry', 'melon', 'orange'}",https://docs.python.org/ko/3/library/stdtypes.html#frozenset.union
91,셋,교집합,intersection,공통,해쉬,셋1.intersection(셋2),"# 두 해쉬셋 정의
fruits1 = {""apple"", ""banana"", ""cherry""}
fruits2 = {""orange"", ""melon"", ""banana""}

# 교집합 출력
print(fruits1.intersection(fruits2))",{'banana'},https://docs.python.org/ko/3/library/stdtypes.html#frozenset.intersection
92,셋,차집합,difference,차,해쉬,셋1.defference(셋2),"# 두 해쉬셋 정의
fruits1 = {""apple"", ""banana"", ""cherry""}
fruits2 = {""orange"", ""melon"", ""banana""}

# 차집합 출력
print(fruits1.difference(fruits2))","{'apple', 'cherry'}",https://docs.python.org/ko/3/library/stdtypes.html#frozenset.difference
93,셋,리스트,변환,list,해쉬,list(셋),"# 해쉬셋 정의
fruits = {""apple"", ""banana"", ""cherry""}

# 리스트로 변환
list(fruits)","['apple', 'cherry', 'banana']",https://docs.python.org/ko/3/library/functions.html#func-list
94,셋,공집합,isjisjoint,공통,해쉬,셋1.isdisjoint(셋2),"# 두 해쉬셋 정의
fruits1 = {""apple"", ""banana"", ""cherry""}
fruits2 = {""orange"", ""melon"", ""banana""}

# 공집합 여부 확인
print(fruits1.isdisjoint(fruits2))",False,https://docs.python.org/ko/3/library/stdtypes.html#frozenset.isdisjoint
95,리스트,컴프리헨션,연산,comprehension,요소,[연산 for 요소 in 리스트],"# 기본 리스트 정의
numbers = [1, 2, 3, 4, 5]

# 각 요소에 2를 곱한 새로운 리스트 생성
doubled_numbers = [x * 2 for x in numbers]

# 결과 출력
print(doubled_numbers)","[2, 4, 6, 8, 10]",https://docs.python.org/ko/3/tutorial/datastructures.html#list-comprehensions
96,리스트,큰 값,max,최대,함수,max(리스트),"# 기본 리스트 정의
numbers = [1, 2, 3, 4, 5]

# 최대값 출력
print(max(numbers))",5,https://docs.python.org/ko/3/library/functions.html#max
97,정규표현식,숫자,추출,\d+,패턴,"re.findall(패턴, 문자)","import re

pattern = ""코드""
text = ""저는 예시코드가 있는 코드지니어스입니다.""

re.findall(pattern, text)","['코드', '코드']",https://docs.python.org/ko/3/library/re.html#regular-expression-syntax
98,리스트,작은 값,min,최소,함수,min(리스트),"# 기본 리스트 정의
numbers = [1, 2, 3, 4, 5]

# 최소값 출력
print(min(numbers))",1,https://docs.python.org/ko/3/library/functions.html#min
99,셋,부분 집합,issubset,부분,집합,셋1.issubset(셋2),"# 두 해쉬셋 정의
fruits1 = {""apple"", ""banana"", ""cherry""}
fruits2 = {""orange"", ""melon"", ""banana""}

# 부분집합 여부 확인
print(fruits1.issubset(fruits2))",False,https://docs.python.org/ko/3/library/stdtypes.html#frozenset.issubset
100,두,집단,평균,가설검정,,"ttest_ind(집단1, 집단2)","import numpy as np
from scipy.stats import ttest_ind

# 집단 1과 집단 2의 데이터를 생성합니다.
np.random.seed(0)  # 재현성을 위해 난수 생성기의 시드를 설정합니다.
group1 = np.random.normal(loc=75, scale=10, size=30)  # 평균 75, 표준편차 10, 30개의 데이터
group2 = np.random.normal(loc=70, scale=15, size=30)  # 평균 70, 표준편차 15, 30개의 데이터

# 두 집단의 평균을 출력해 봅니다.
print(f""Group 1 mean: {np.mean(group1):.2f}"")
print(f""Group 2 mean: {np.mean(group2):.2f}"")

# t-검정을 수행합니다.
t_stat, p_value = ttest_ind(group1, group2)

# 결과를 출력합니다.
print(f""T-statistic: {t_stat:.2f}"")
print(f""P-value: {p_value:.4f}"")","Group 1 mean: 79.43
Group 2 mean: 65.66
T-statistic: 4.29
P-value: 0.0001",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html
101,가설검정,p값,0.05,귀무가설,기각,"if p_value < 0.05: print(""귀무가설 기각"")","import numpy as np
from scipy.stats import ttest_ind

# 두 집단의 데이터를 생성합니다.
np.random.seed(0)
group1 = np.random.normal(loc=75, scale=10, size=30)  # 평균 75, 표준편차 10, 30개의 데이터
group2 = np.random.normal(loc=70, scale=15, size=30)  # 평균 70, 표준편차 15, 30개의 데이터

# t-검정을 수행합니다.
t_stat, p_value = ttest_ind(group1, group2)

# 유의수준 0.05를 기준으로 가설 검정 결과를 출력합니다.
alpha = 0.05
if p_value < alpha:
    print(""귀무가설 기각: 두 집단 간의 평균 차이가 통계적으로 유의미합니다."")
else:
    print(""귀무가설 채택: 두 집단 간의 평균 차이가 통계적으로 유의미하지 않습니다."")
","귀무가설 기각: 두 집단 간의 평균 차이가 통계적으로 유의미합니다.
",https://docs.python.org/ko/3/library/statistics.html#hypothesis-testing
102,가설검정,정규분포,수행,함수,,"stats.ttest_1samp(데이터, 평균)","import numpy as np
from scipy import stats

# 데이터 생성
np.random.seed(0)
data = np.random.normal(loc=75, scale=10, size=30)  # 평균 75, 표준편차 10, 30개의 데이터

# 검정할 평균값
mean_value = 70

# t-검정 수행
t_stat, p_value = stats.ttest_1samp(data, mean_value)

# 결과 출력
print(f""데이터 평균: {np.mean(data):.2f}"")
print(f""검정 평균값: {mean_value}"")
print(f""T-statistic: {t_stat:.2f}"")
print(f""P-value: {p_value:.4f}"")

# 유의수준 0.05를 기준으로 가설 검정 결과를 출력합니다.
alpha = 0.05
if p_value < alpha:
    print(f""귀무가설 기각: 데이터의 평균이 {mean_value}와(과) 유의미하게 다릅니다."")
else:
    print(f""귀무가설 채택: 데이터의 평균이 {mean_value}와(과) 유의미하게 다르지 않습니다."")","데이터 평균: 79.43
검정 평균값: 70
T-statistic: 4.69
P-value: 0.0001
귀무가설 기각: 데이터의 평균이 70와(과) 유의미하게 다릅니다.
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_1samp.html
103,파이썬,비모수적,가설검정,수행,함수,"stats.mannwhitneyu(샘플1, 샘플2)","import numpy as np
from scipy import stats

# 두 개의 독립적인 샘플 데이터 생성
np.random.seed(0)
sample1 = np.random.normal(loc=75, scale=10, size=30)  # 평균 75, 표준편차 10, 30개의 데이터
sample2 = np.random.normal(loc=70, scale=15, size=30)  # 평균 70, 표준편차 15, 30개의 데이터

# Mann-Whitney U 검정 수행
statistic, p_value = stats.mannwhitneyu(sample1, sample2)

# 결과 출력
print(f""Mann-Whitney U statistic: {statistic:.2f}"")
print(f""P-value: {p_value:.4f}"")

# 유의수준 0.05를 기준으로 가설 검정 결과를 출력합니다.
alpha = 0.05
if p_value < alpha:
    print(""귀무가설 기각: 두 샘플 간의 분포에 유의미한 차이가 있습니다."")
else:
    print(""귀무가설 채택: 두 샘플 간의 분포에 유의미한 차이가 없습니다."")","Mann-Whitney U statistic: 722.00
P-value: 0.0001
귀무가설 기각: 두 샘플 간의 분포에 유의미한 차이가 있습니다.
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html
104,일변량,다변량,가설검정,차이점,,threshold = 평균벡터 + z_value * np.sqrt(np.diag(공분산행렬)),"import numpy as np
from scipy.stats import multivariate_normal, norm

# 다변량 정규 분포의 평균 벡터와 공분산 행렬 생성
mean = np.array([0, 0])
cov = np.array([[1, 0.5], [0.5, 2]])

# 신뢰수준과 양측 검정의 경우
confidence_level = 0.95
alpha = 1 - confidence_level
z_value = norm.ppf(1 - alpha / 2)

# 다변량 정규 분포의 신뢰구간 경계값 계산
threshold = mean + z_value * np.sqrt(np.diag(cov))

print(f""다변량 정규 분포의 {confidence_level * 100}% 신뢰구간 경계값 (양측 검정):\n{threshold}"")
","다변량 정규 분포의 95.0% 신뢰구간 경계값 (양측 검정):
[1.95996398 2.77180765]
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.multivariate_normal.html
105,파이썬,단측,가설검정,수행,,"stats.ttest_rel(샘플1, 샘플2, 대안='less')","import numpy as np
from scipy import stats

# 샘플 데이터 생성
sample1 = np.array([10, 12, 15, 8, 11])
sample2 = np.array([8, 11, 14, 7, 10])

# stats.ttest_rel 함수 사용
t_statistic, p_value = stats.ttest_rel(sample1, sample2, alternative='less')

print(f""t-statistic: {t_statistic}"")
print(f""p-value: {p_value}"")

if p_value < 0.05:
    print(""귀무가설 기각: 샘플1의 평균이 샘플2의 평균보다 작다는 근거가 충분하다."")
else:
    print(""귀무가설 채택: 샘플1의 평균이 샘플2의 평균보다 작다는 근거가 부족하다."")","t-statistic: 5.999999999999998
p-value: 0.9980587314765198
귀무가설 채택: 샘플1의 평균이 샘플2의 평균보다 작다는 근거가 부족하다.
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html
106,카이제곱,검정,사용,,,scipy.stats.chi2_contingency(데이터),"import numpy as np
from scipy.stats import chi2_contingency

# 예시 데이터 (2x2 contingency table)
# 이 예시에서는 두 변수 A와 B가 있고 각각의 변수가 두 가지 수준을 가집니다.
# A 변수: A1, A2
# B 변수: B1, B2
# 데이터는 다음과 같이 구성됩니다:
#          B1   B2
# ----------------
# A1 |   10   20
# A2 |   15   25
observed = np.array([[10, 20],
                     [15, 25]])

# chi2_contingency 함수 사용
chi2_stat, p_val, dof, expected = chi2_contingency(observed)

print(f""Chi-square statistic: {chi2_stat}"")","Chi-square statistic: 0.011666666666666653
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html
107,회귀분석,가설검정,사용,,,"statsmodels.api.OLS(종속변수, 독립변수).fit().summary2().tables[0]","import statsmodels.api as sm
import numpy as np
import pandas as pd

# 예시 데이터 생성
np.random.seed(0)
x = np.random.rand(100)
y = 2.5 * x + np.random.normal(size=100)

# 독립변수와 종속변수를 데이터프레임으로 변환
data = pd.DataFrame({'x': x, 'y': y})

# 독립변수와 종속변수 설정
X = data['x']
y = data['y']

# 상수항 추가
X = sm.add_constant(X)

# OLS 모델 적합
model = sm.OLS(y, X).fit()

# 결과 요약 테이블
summary_table = model.summary2().tables[0]
print(summary_table)","                     0                 1                    2         3
0               Model:               OLS      Adj. R-squared:     0.325
1  Dependent Variable:                 y                 AIC:  287.0287
2                Date:  2024-06-10 11:41                 BIC:  292.2390
3    No. Observations:               100      Log-Likelihood:   -141.51
4            Df Model:                 1         F-statistic:     48.74
5        Df Residuals:                98  Prob (F-statistic):  3.51e-10
6           R-squared:             0.332               Scale:    1.0127
",https://www.statsmodels.org/stable/user-guide.html
108,이분법,이산적,데이터,성공,확률,"p_value = binomtest(성공횟수, n=시도횟수, p=성공확률, alternative='two-sided')","from scipy.stats import binomtest

# 예시 데이터
successes = 52  # 성공 횟수
n_trials = 100  # 시도 횟수
p_success = 0.5  # 성공 확률 (귀무가설에서 가정한 성공 확률)
alternative = 'two-sided'  # 양측 검정

# 이항 검정 수행
p_value = binomtest(successes, n=n_trials, p=p_success, alternative=alternative)
print(f""P-value: {p_value}"")","P-value: BinomTestResult(k=52, n=100, alternative='two-sided', statistic=0.52, pvalue=0.7643534344026669)
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binomial_test.html
109,정규분포,중심극한정리,표본,크기,,"scipy.stats.mannwhitneyu(데이터1, 데이터2)","from scipy.stats import mannwhitneyu

# 예시 데이터
data1 = [18, 20, 21, 22, 25, 26, 28, 30, 31, 33]
data2 = [23, 24, 25, 27, 28, 30, 31, 32, 34, 35]

# Mann-Whitney U 검정 수행
statistic, p_value = mannwhitneyu(data1, data2)
print(f""검정 통계량: {statistic}"")
print(f""P-value: {p_value}"")","검정 통계량: 30.0
P-value: 0.1398679114797594
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html
110,ANOVA,분산분석,통계적,검증,가설검정,"scipy.stats.f_oneway(그룹1, 그룹2, 그룹3)","from scipy.stats import f_oneway

# 예시 데이터
group1 = [18, 20, 21, 22, 25]
group2 = [23, 24, 25, 27, 28]
group3 = [30, 31, 32, 34, 35]

# One-way ANOVA 분석
statistic, p_value = f_oneway(group1, group2, group3)
print(f""One-way ANOVA 통계량: {statistic}"")
print(f""P-value: {p_value}"")","One-way ANOVA 통계량: 31.385620915032685
P-value: 1.708755456720858e-05
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.f_oneway.html
111,일표본,t-검정,표본,정규분포,평균,scipy.stats.shapiro(데이터),"from scipy import stats
import numpy as np

# 예시 데이터
data = np.random.normal(loc=0, scale=1, size=100)

# Shapiro-Wilk 정규성 검정
statistic, p_value = stats.shapiro(data)
print(f""Shapiro-Wilk 통계량: {statistic}"")
print(f""P-value: {p_value}"")

# 결과 해석
alpha = 0.05
if p_value < alpha:
    print(""귀무가설을 기각합니다. 데이터는 정규 분포를 따르지 않을 가능성이 큽니다."")
else:
    print(""귀무가설을 기각할 수 없습니다. 데이터가 정규 분포를 따를 가능성이 있습니다."")","Shapiro-Wilk 통계량: 0.9909581542015076
P-value: 0.741660475730896
귀무가설을 기각할 수 없습니다. 데이터가 정규 분포를 따를 가능성이 있습니다.
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html
112,이표본,독립적인,표본,정규분포,평균,"scipy.stats.wilcoxon(데이터1, 데이터2)","from scipy import stats
import numpy as np

# 예시 데이터
data1 = np.array([6, 8, 14, 17, 18, 23, 25, 30, 32, 35])
data2 = np.array([3, 6, 7, 8, 10, 12, 16, 18, 21, 25])

# Wilcoxon 부호 순위 검정
statistic, p_value = stats.wilcoxon(data1, data2)

print(f""검정 통계량: {statistic}"")
print(f""P-value: {p_value}"")

# 결과 해석
alpha = 0.05
if p_value < alpha:
    print(""귀무가설을 기각합니다. 두 집단 간에는 차이가 있을 가능성이 있습니다."")
else:
    print(""귀무가설을 기각할 수 없습니다. 두 집단 간에는 차이가 없을 가능성이 있습니다."")","검정 통계량: 0.0
P-value: 0.001953125
귀무가설을 기각합니다. 두 집단 간에는 차이가 있을 가능성이 있습니다.
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wilcoxon.html
113,회귀분석,NumPy,Pandas,Matplotlib,Scikit-learn,"import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn","import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import sklearn",-,https://scikit-learn.org/stable/getting_started.html
114,성능,평가,R2,RMSE,MAE,"from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error","from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Example data
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]

# Calculate metrics
r2 = r2_score(y_true, y_pred)
mse = mean_squared_error(y_true, y_pred)
mae = mean_absolute_error(y_true, y_pred)

# Print results
print(f'R^2 Score: {r2:.4f}')
print(f'Mean Squared Error: {mse:.4f}')
print(f'Mean Absolute Error: {mae:.4f}')","R^2 Score: 0.9486
Mean Squared Error: 0.3750
Mean Absolute Error: 0.5000
",https://scikit-learn.org/stable/api/sklearn.metrics.html
115,회귀모델,훈련,로드,초기화,평가,"model = LinearRegression()
model.fit(독립변수, 종속변수)","import numpy as np
from sklearn.linear_model import LinearRegression

# Example data
X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])
# y = 1 * x_0 + 2 * x_1 + 3
y = np.dot(X, np.array([1, 2])) + 3

# Create a linear regression model
model = LinearRegression()

# Fit the model
model.fit(X, y)

# Print the coefficients and intercept
print(f""Coefficients: {model.coef_}"")
print(f""Intercept: {model.intercept_}"")

# Predict using the model
X_test = np.array([[3, 5]])
y_pred = model.predict(X_test)
print(f""Prediction for {X_test}: {y_pred}"")","Coefficients: [1. 2.]
Intercept: 3.0000000000000018
Prediction for [[3 5]]: [16.]
",https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
116,검증,데이터,세트,회귀분석,신뢰성,from sklearn.model_selection import train_test_split,"import numpy as np
from sklearn.model_selection import train_test_split

# 예시 데이터
X = np.arange(10).reshape(-1, 1)  # 특성 (열 벡터로 변환)
y = np.array([0, 1, 0, 1, 0, 1, 0, 1, 0, 1])  # 타겟 변수

# 데이터를 학습 세트와 테스트 세트로 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 학습 세트와 테스트 세트의 형태 출력
print(f""X_train shape: {X_train.shape}, y_train shape: {y_train.shape}"")
print(f""X_test shape: {X_test.shape}, y_test shape: {y_test.shape}"")","X_train shape: (8, 1), y_train shape: (8,)
X_test shape: (2, 1), y_test shape: (2,)
",https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#train-test-split
117,회귀,저장,로드,pickle,모델,"with open('경로.파일명', '바이너리 쓰기 모드') as f:
    pickle.dump(model, f)","import pickle
from sklearn.linear_model import LinearRegression
import numpy as np

# 예시 데이터 생성
X = np.array([[1], [2], [3], [4], [5]])
y = np.array([2, 4, 6, 8, 10])

# 모델 생성 및 학습
model = LinearRegression()
model.fit(X, y)

# 모델을 pickle 파일로 저장
with open('model.pkl', 'wb') as f:
    pickle.dump(model, f)

print(""모델이 저장되었습니다."")",모델이 저장되었습니다.,https://docs.python.org/ko/3/library/pickle.html
118,파이썬,scikit-learn,라이브러리,회귀분석,,"from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(데이터, 타깃)","from sklearn.linear_model import LinearRegression

# 예시 데이터 생성
import numpy as np
X = np.array([[1], [2], [3], [4], [5]])  # 특성 데이터
y = np.array([2, 3.5, 3.3, 4.8, 5.1])     # 타겟 데이터

# 선형 회귀 모델 생성 및 학습
reg = LinearRegression()
reg.fit(X, y)

# 학습된 모델을 사용하여 예측
X_new = np.array([[6], [7], [8]])  # 새로운 데이터 예측
predictions = reg.predict(X_new)

print(f""예측값: {predictions}"")","예측값: [5.99 6.74 7.49]
",https://scikit-learn.org/stable/api/sklearn.linear_model.html
119,scikit-learn,PolynomialFeatures,LinearRegression,다항,모델,"poly = PolynomialFeatures(도수)
X_poly = poly.fit_transform(데이터)
reg = LinearRegression()
reg.fit(X_poly, 타깃)","from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import numpy as np

# 예시 데이터 생성
X = np.array([[1], [2], [3], [4], [5]])  # 특성 데이터
y = np.array([2, 3.5, 3.3, 4.8, 5.1])     # 타겟 데이터

# 다항 특성 추가
degree = 3  # 다항식의 차수
poly = PolynomialFeatures(degree)
X_poly = poly.fit_transform(X)

# 다항 회귀 모델 생성 및 학습
reg = LinearRegression()
reg.fit(X_poly, y)

# 학습된 모델을 사용하여 예측
X_new = np.array([[6], [7], [8]])  # 새로운 데이터 예측
X_new_poly = poly.transform(X_new)  # 기존의 PolynomialFeatures 객체로 변환 필요
predictions = reg.predict(X_new_poly)

print(f""예측값: {predictions}"")",예측값: [ 6.34  8.14 10.84],https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html
120,회귀,학습,새로운,데이터,예측,"예측_데이터 = [[새로운_데이터, ...]]
예측_값 = reg.predict(예측_데이터)","from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import numpy as np

# 예시 데이터 생성
X = np.array([[1], [2], [3], [4], [5]])  # 특성 데이터
y = np.array([2, 3.5, 3.3, 4.8, 5.1])     # 타겟 데이터

# 다항 특성 추가
degree = 3  # 다항식의 차수
poly = PolynomialFeatures(degree)
X_poly = poly.fit_transform(X)

# 다항 회귀 모델 생성 및 학습
reg = LinearRegression()
reg.fit(X_poly, y)

# 예측 데이터 생성
X_new = np.array([[6], [7], [8]])  # 새로운 데이터 예측
X_new_poly = poly.transform(X_new)  # 기존의 PolynomialFeatures 객체로 변환 필요

# 예측 수행
predictions = reg.predict(X_new_poly)

print(f""예측값: {predictions}"")","예측값: [ 6.34  8.14 10.84]
",https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict
121,회귀,저장,로드,joblib,scikit-learn,"import joblib
joblib.dump(reg, ""모델_이름.pkl"")
새로운_reg = joblib.load(""모델_이름.pkl"")","from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.externals import joblib
import numpy as np

# 예시 데이터 생성
X = np.array([[1], [2], [3], [4], [5]])  # 특성 데이터
y = np.array([2, 3.5, 3.3, 4.8, 5.1])     # 타겟 데이터

# 다항 특성 추가
degree = 3  # 다항식의 차수
poly = PolynomialFeatures(degree)
X_poly = poly.fit_transform(X)

# 다항 회귀 모델 생성 및 학습
reg = LinearRegression()
reg.fit(X_poly, y)

# 모델 저장
joblib.dump(reg, ""model.pkl"")

# 모델 로드
new_reg = joblib.load(""model.pkl"")","모델이 저장되었습니다.
모델이 로드되었습니다.",https://scikit-learn.org/stable/model_persistence.html#
122,특성,회귀 모델,중요도,파악,,"from sklearn.feature_selection import f_regression
importance = f_regression(데이터, 타깃)","from sklearn.feature_selection import f_regression
import numpy as np

# 예시 데이터 생성
X = np.array([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6]])  # 특성 데이터
y = np.array([2, 3.5, 3.3, 4.8, 5.1])                   # 타겟 데이터

# f_regression을 사용하여 특성의 중요도 계산
importance, p_values = f_regression(X, y)

# 결과 출력
print(""특성 중요도:"", importance)
print(""p-values:"", p_values)","특성 중요도: [26.9138756 26.9138756]
p-values: [0.01390798 0.01390798]
",https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.f_regression.html#f-regression
123,scikit-learn,predict,신뢰구간,반환,,"model.predict(예측 값, 표준변차반환여ㅜ=True)","import numpy as np
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

# 예시 데이터 생성
rng = np.random.RandomState(4)
X = rng.uniform(0, 5, 10)[:, np.newaxis]
y = np.sin(X).ravel()

# 가우시안 프로세스 모델 정의
kernel = C(1.0, (1e-4, 1e1)) * RBF(0.5, (1e-2, 1e2))
model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-2)

# 모델 학습
model.fit(X, y)

# 예측 및 표준 편차 반환
X_pred = np.linspace(0, 5, 100)[:, np.newaxis]
y_pred, std = model.predict(X_pred, return_std=True)

# 결과 출력
for i in range(5):
    print(f""예측 값: {y_pred[i]:.4f}, 표준 편차: {std[i]:.4f}"")","예측 값: 0.0331, 표준 편차: 0.0996
예측 값: 0.0749, 표준 편차: 0.0948
예측 값: 0.1172, 표준 편차: 0.0908
예측 값: 0.1600, 표준 편차: 0.0876
예측 값: 0.2031, 표준 편차: 0.0851
",https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict
124,R^2,예측,변동성,설명,측정값,"r2_score = r2_score(y_사실, y_예측)","from sklearn.metrics import r2_score

# 예측 값
y_pred = [3, -0.5, 2, 7]
# 실제 값
y_true = [2.5, 0.0, 2, 8]

# R^2 점수 계산
r2 = r2_score(y_true, y_pred)

print(f'R^2 점수: {r2:.4f}')",R^2 점수: 0.9574,https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html
125,가중치,예측,목표,절편,변수,"model = LinearRegression()
model.fit(x, y)
print(model.계수, model.절편)","from sklearn.linear_model import LinearRegression

# 예시 데이터
x = [[1], [2], [3], [4]]  # 특성
y = [2, 4, 6, 8]          # 타겟

# 모델 초기화
model = LinearRegression()

# 모델 훈련
model.fit(x, y)

# 학습된 모델의 계수(coefficient)와 절편(intercept) 출력
print(""계수(coef):"", model.coef_)
print(""절편(intercept):"", model.intercept_)","계수(coef): [2.]
절편(intercept): -1.7763568394002505e-15
",https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html
126,교차,과대적합,방지,훈련,검증,"model = LinearRegression()
scores = cross_val_score(model, 특성, 타겟, 교차검증갯수=2)","from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression

# 예시 데이터
x = [[1], [2], [3], [4]]  # 특성
y = [2, 4, 6, 8]          # 타겟

# 모델 초기화
model = LinearRegression()

# 교차 검증 점수 계산
scores = cross_val_score(model, x, y, cv=2)

# 각 교차 검증 결과 출력
print(""교차 검증 점수:"", scores)
print(""평균 교차 검증 점수:"", scores.mean())","교차 검증 점수: [1. 1.]
평균 교차 검증 점수: 1.0",https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html
127,주성분,분석,차원,상관관계,변수,"pca = PCA(선택할주성분갯수=2)
x_transformed = pca.fit_transform(x)
model = LinearRegression()
model.fit(x_transformed, y)","import numpy as np
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression

# 예제 데이터
x = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [10, 11, 12]])

y = np.array([4, 5, 6, 7])

# PCA를 사용하여 차원을 축소합니다 (2개의 주성분만 선택)
pca = PCA(n_components=2)
x_transformed = pca.fit_transform(x)

# 변환된 데이터로 선형 회귀 모델을 초기화하고 훈련합니다
model = LinearRegression()
model.fit(x_transformed, y)

# 모델의 회귀 계수와 절편을 출력합니다
print(""회귀 계수 (기울기):"", model.coef_)
print(""절편:"", model.intercept_)","회귀 계수 (기울기): [-0.19245009  0.        ]
절편: 5.5",https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html
128,정규화,예측,척도,성능,안정성,"scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)","import numpy as np
from sklearn.preprocessing import StandardScaler

# 예제 데이터
x = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [10, 11, 12]])

# StandardScaler를 사용하여 데이터를 표준화합니다
scaler = StandardScaler()
x_scaled = scaler.fit_transform(x)

# 변환된 데이터를 출력합니다
print(""원본 데이터:\n"", x)
print(""\n표준화된 데이터:\n"", x_scaled)","원본 데이터:
 [[ 1  2  3]
 [ 4  5  6]
 [ 7  8  9]
 [10 11 12]]

표준화된 데이터:
 [[-1.34164079 -1.34164079 -1.34164079]
 [-0.4472136  -0.4472136  -0.4472136 ]
 [ 0.4472136   0.4472136   0.4472136 ]
 [ 1.34164079  1.34164079  1.34164079]]
",https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
129,모델,선택,방법,비교,과정,"models = [LinearRegression(), Ridge(), Lasso()]
scores = []
for model in models:
    scores.append(cross_val_score(model, 특성, 타겟, 교차검증갯수=2).mean())
best_model = models[np.argmax(scores)]","import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso

# 예제 데이터
x = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9],
              [10, 11, 12]])
y = np.array([4, 5, 6, 7])

# 모델들
models = [LinearRegression(), Ridge(), Lasso()]

# 교차 검증을 통한 평가
scores = []
for model in models:
    score = cross_val_score(model, x, y, cv=2).mean()
    scores.append(score)

# 가장 성능이 좋은 모델 선택
best_model = models[np.argmax(scores)]

print(""Cross-validation scores:"")
for i, model in enumerate(models):
    print(f""{model.__class__.__name__}: {scores[i]}"")

print(f""\n가장 성능이 좋은 모델: {best_model.__class__.__name__}"")","Cross-validation scores:
LinearRegression: 1.0
Ridge: 0.9191438763376929
Lasso: -16.0

가장 성능이 좋은 모델: LinearRegression",https://scikit-learn.org/stable/user_guide.html
130,과적합,과소적합,교차 검증,정규화,조기 종료,"model = LinearRegression()
model.set_params(max_iter=1000)
early_stopping = EarlyStopping(patience=5)
model.fit(x, y, callbacks=[early_stopping])","from sklearn.linear_model import LinearRegression
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from sklearn.base import clone

class EarlyStopping:
    def __init__(self, patience=5):
        self.patience = patience
        self.best_model = None
        self.best_loss = float('inf')
        self.current_patience = 0

    def __call__(self, model, X_val, y_val):
        y_pred = model.predict(X_val)
        loss = mean_squared_error(y_val, y_pred)
        
        if loss < self.best_loss:
            self.best_loss = loss
            self.best_model = clone(model)
            self.best_model.fit(X_val, y_val)  # X_val, y_val로 적합시킵니다.
            self.current_patience = 0
        else:
            self.current_patience += 1
        
        if self.current_patience > self.patience:
            return True  # 조기 종료 신호 반환
        else:
            return False

# 데이터 준비
x, y = make_regression(n_samples=100, n_features=1, noise=0.1, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)

# 모델 초기화
model = LinearRegression()

# 조기 종료 콜백
early_stopping = EarlyStopping(patience=5)

# 모델 학습 및 조기 종료 적용
for i in range(100):  # 예시를 위해 100번의 에포크 수행
    model.fit(X_train, y_train)
    if early_stopping(model, X_val, y_val):
        print(f""조기 종료: 에포크 {i+1}"")
        break

# 최적의 모델에서 예측 수행
best_model = early_stopping.best_model
y_pred = best_model.predict(X_val)
mse = mean_squared_error(y_val, y_pred)
print(f""최종 평가 MSE: {mse}"")","조기 종료: 에포크 7
최종 평가 MSE: 0.0076766525512715015
",https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html
131,릿지 회귀,과적합,알고리즘,릿지,회귀,"from sklearn.linear_model import Ridge
모델 = Ridge(정규화강도조절=0.1)
모델.fit(X, y)","from sklearn.linear_model import Ridge
import numpy as np

# 예제 데이터 생성
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# Ridge 회귀 모델 초기화 및 학습
model = Ridge(alpha=0.1)  # alpha는 정규화 강도를 조절하는 매개변수입니다.
model.fit(X, y)

# 학습된 모델을 사용하여 예측
X_new = np.array([[0], [2]])
y_pred = model.predict(X_new)

print(f""Ridge 모델의 계수 (기울기): {model.coef_}"")
print(f""Ridge 모델의 절편: {model.intercept_}"")
print(f""예측값: {y_pred}"")","Ridge 모델의 계수 (기울기): [[2.76223165]]
Ridge 모델의 절편: [4.22250784]
예측값: [[4.22250784]
 [9.74697114]]
",https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html
132,라쏘 회귀,변수 선택,알고리즘,라쏘,선택,"from sklearn.linear_model import Lasso
모델 = Lasso(정규화강도조절=0.1)
모델.fit(X, y)","from sklearn.linear_model import Lasso
import numpy as np

# 예제 데이터 생성
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)

# Lasso 회귀 모델 초기화 및 학습
model = Lasso(alpha=0.1)  # alpha는 정규화 강도를 조절하는 매개변수입니다.
model.fit(X, y)

# 학습된 모델을 사용하여 예측
X_new = np.array([[0], [2]])
y_pred = model.predict(X_new)

print(f""Lasso 모델의 계수 (기울기): {model.coef_}"")
print(f""Lasso 모델의 절편: {model.intercept_}"")
print(f""예측값: {y_pred}"")","Lasso 모델의 계수 (기울기): [2.48477396]
Lasso 모델의 절편: [4.48341837]
예측값: [4.48341837 9.45296628]
",https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html
133,scikit-learn,cluster,AgglomerativeClustering,상관관계,군집화,"from sklearn.cluster import AgglomerativeClustering
 clustering = AgglomerativeClustering클러스터생성갯수=3)","from sklearn.cluster import AgglomerativeClustering
import numpy as np

# 예제 데이터 생성
np.random.seed(0)
X = np.random.rand(10, 2)  # 10개의 데이터 포인트, 각각 2개의 특성

# 계층적 군집화 모델 초기화
clustering = AgglomerativeClustering(n_clusters=3)

# 모델을 데이터에 fitting
clustering.fit(X)

# 예측된 클러스터 레이블 얻기
cluster_labels = clustering.labels_

print(""각 데이터 포인트의 클러스터 레이블:"")
print(cluster_labels)","각 데이터 포인트의 클러스터 레이블:
[0 2 0 0 2 2 0 1 0 0]
",https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html
134,상관계수,함수,계산,pearsonr,,"scipy.stats.pearsonr(X, Y)","from scipy.stats import pearsonr
import numpy as np

# 예제 데이터 생성
np.random.seed(0)
X = np.random.rand(100)  # 첫 번째 변수
Y = X + np.random.rand(100)  # 두 번째 변수 (첫 번째 변수와 약간의 노이즈)

# 피어슨 상관 계수 계산
corr, p_value = pearsonr(X, Y)

print(f""피어슨 상관 계수: {corr}"")
print(f""상관 관계의 유의성을 나타내는 p-value: {p_value}"")","피어슨 상관 계수: 0.6991720710419991
상관 관계의 유의성을 나타내는 p-value: 5.962448746607755e-16",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html
135,상관계수,시각화,seaborn,,,"seaborn.heatmap(데이터프레임,  데이터 값을 표시할지 여부=True, 색상 맵설정=""coolwarm"", 셀 간격 설정=.5)","import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# 예제 데이터 생성
np.random.seed(0)
data = pd.DataFrame(np.random.randn(10, 10), columns=[f""Column_{i+1}"" for i in range(10)])

# 히트맵 그리기
plt.figure(figsize=(10, 8))
sns.heatmap(data, annot=True, cmap=""coolwarm"", linewidths=.5)
plt.title('Heatmap of a DataFrame')
plt.show()
",-,https://seaborn.pydata.org/generated/seaborn.heatmap.html
136,HCA,위계적 군집 분석,,상관 관계,식별,scipy.cluster.hierarchy.linkage(데이터),"import numpy as np
from scipy.cluster.hierarchy import linkage, dendrogram
import matplotlib.pyplot as plt

# 예시 데이터 생성
np.random.seed(0)
X = np.random.rand(10, 2)  # 10개의 데이터 포인트, 각각 2개의 특성

# linkage 함수를 사용하여 계층적 클러스터링 수행
Z = linkage(X, method='ward', metric='euclidean')

# 덴드로그램(dendrogram) 그리기
plt.figure(figsize=(10, 5))
dendrogram(Z)
plt.title('Hierarchical Clustering Dendrogram')
plt.xlabel('Sample index')
plt.ylabel('Cluster distance')
plt.show()",-,https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html
137,다중공선성,변수 선택,정규화,상관 분석,왜곡,statsmodels.stats.outliers_influence.variance_inflation_factor(배열),"import numpy as np
import pandas as pd
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

# 예시 데이터 생성
np.random.seed(0)
data = pd.DataFrame(np.random.randn(100, 4), columns=['X1', 'X2', 'X3', 'X4'])

# X1을 기준으로 나머지 변수들을 선형 조합하여 X5를 생성 (다중 공선성 발생)
data['X5'] = 2 * data['X1'] + 3 * data['X2'] + 4 * data['X3'] + 5 * data['X4']

# 독립 변수와 종속 변수 분리
X = data[['X1', 'X2', 'X3', 'X4']]
y = data['X5']

# VIF 계산
vif = pd.DataFrame()
vif[""Features""] = X.columns
vif[""VIF""] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

# 결과 출력
print(vif)","  Features       VIF
0       X1  1.037236
1       X2  1.066275
2       X3  1.077394
3       X4  1.008288
",https://www.statsmodels.org/stable/generated/statsmodels.stats.outliers_influence.variance_inflation_factor.html
138,시계열 데이터,추세,이동 평균,제거,,"df[""차이분석""].rolling(window=5).mean()","import pandas as pd
import numpy as np

# 예시 데이터 생성
np.random.seed(0)
dates = pd.date_range('1/1/2020', periods=10)
df = pd.DataFrame(np.random.randn(10, 1), index=dates, columns=['차이분석'])

# 이동 평균 계산 (window=5)
rolling_mean = df['차이분석'].rolling(window=5).mean()

# 결과 출력
print(rolling_mean)","2020-01-01         NaN
2020-01-02         NaN
2020-01-03         NaN
2020-01-04         NaN
2020-01-05    1.450280
2020-01-06    0.902014
2020-01-07    1.012000
2020-01-08    0.785981
2020-01-09    0.317158
2020-01-10    0.025767
Freq: D, Name: 차이분석, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html
139,푸리에 변환,시계열 데이터,주기,식별,분석 도구,"from scipy.fftpack import fft
fft(df[""차이분석""])","import numpy as np
from scipy.fftpack import fft
import matplotlib.pyplot as plt

# 예시 데이터 생성
np.random.seed(0)
time_step = 0.02
period = 5.
time_vec = np.arange(0, 20, time_step)
signal = (np.sin(2 * np.pi / period * time_vec)
          + 0.5 * np.random.randn(time_vec.size))

# FFT 계산
fft_signal = fft(signal)

# 주파수 축 계산
sample_freq = fftfreq(signal.size, d=time_step)
pidxs = np.where(sample_freq > 0)
freqs = sample_freq[pidxs]
power = np.abs(fft_signal)[pidxs]

# 시각화
plt.figure(figsize=(10, 5))
plt.plot(freqs, power)
plt.xlabel('Frequency [Hz]')
plt.ylabel('Power')
plt.title('FFT of signal')
plt.show()",-,https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.fft.html
140,ARIMA,시계열 데이터,예측,기법,ARIMA 모델,"from statsmodels.tsa.arima.model import ARIMA
model = ARIMA(df[""차이분석""], order=(5, 1, 0))
model.fit()","from statsmodels.tsa.arima.model import ARIMA
import pandas as pd
import numpy as np

# 예시 데이터 생성
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=365)
data = np.random.randn(365).cumsum()
df = pd.DataFrame(data, index=dates, columns=['차이분석'])

# ARIMA 모델 구성
model = ARIMA(df[""차이분석""], order=(5, 1, 0))

# ARIMA 모델 피팅
result = model.fit()

# ARIMA 모델 요약 정보 출력
print(result.summary())","                               SARIMAX Results                                
==============================================================================
Dep. Variable:                   차이분석   No. Observations:                  365
Model:                 ARIMA(5, 1, 0)   Log Likelihood                -493.861
Date:                Mon, 10 Jun 2024   AIC                            999.722
Time:                        13:12:37   BIC                           1023.105
Sample:                    01-01-2023   HQIC                          1009.016
                         - 12-31-2023                                         
Covariance Type:                  opg                                         
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1         -0.0545      0.055     -0.994      0.320      -0.162       0.053
ar.L2         -0.0279      0.054     -0.515      0.606      -0.134       0.078
ar.L3          0.0297      0.053      0.558      0.577      -0.075       0.134
ar.L4         -0.0898      0.053     -1.693      0.091      -0.194       0.014
ar.L5          0.0517      0.054      0.965      0.334      -0.053       0.157
sigma2         0.8829      0.058     15.107      0.000       0.768       0.997
===================================================================================
Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                 8.59
Prob(Q):                              0.95   Prob(JB):                         0.01
Heteroskedasticity (H):               0.97   Skew:                             0.21
Prob(H) (two-sided):                  0.88   Kurtosis:                         3.63
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
",https://www.statsmodels.org/dev/generated/statsmodels.tsa.arima.model.ARIMA.html
141,자기 상관 함수,시계열 데이터,상관 관계,시계열,상관관계,"from statsmodels.tsa.stattools import acf
acf(df[""차이분석""])","import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import acf
import matplotlib.pyplot as plt

# 예시 데이터 생성
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=365)
data = np.random.randn(365).cumsum()
df = pd.DataFrame(data, index=dates, columns=['차이분석'])

# ACF 계산
lags = 40  # 자기상관 함수를 계산할 최대 시차
acf_vals = acf(df[""차이분석""], nlags=lags)

# ACF 그래프 그리기
plt.figure(figsize=(10, 5))
plt.stem(np.arange(lags + 1), acf_vals)
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.title('Autocorrelation Function (ACF)')
plt.show()",-,https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.acf.html
142,디키-풀러 검정,시계열 데이터,정상성,시계열,디키-풀러,"from statsmodels.tsa.stattools import adfuller
adfuller(df[""차이분석""])","import pandas as pd
import numpy as np
from statsmodels.tsa.stattools import adfuller

# 예시 데이터 생성
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=365)
data = np.random.randn(365).cumsum()
df = pd.DataFrame(data, index=dates, columns=['차이분석'])

# ADF 검정 수행
result = adfuller(df[""차이분석""])

# 결과 출력
print('ADF 검정 통계량 (ADF Statistic):', result[0])
print('P-값 (p-value):', result[1])
print('사용된 시차 (Number of Lags Used):', result[2])
print('관측 수 (Number of Observations Used):', result[3])
print('임계값 (Critical Values):')
for key, value in result[4].items():
    print(f'   {key}: {value}')

# 결과 해석
print('\n결과 해석:')
print(f'ADF 검정 통계량 (ADF Statistic): {result[0]}')
print(f'P-값 (p-value): {result[1]}')

if result[1] < 0.05:
    print('=> 유의수준 5%에서 귀무가설을 기각할 수 있습니다. => 시계열 데이터는 안정적이지 않습니다.')
else:
    print('=> 유의수준 5%에서 귀무가설을 기각할 수 없습니다. => 시계열 데이터는 안정적입니다.')","ADF 검정 통계량 (ADF Statistic): -1.4763584158714853
P-값 (p-value): 0.5451723991122808
사용된 시차 (Number of Lags Used): 0
관측 수 (Number of Observations Used): 364
임계값 (Critical Values):
   1%: -3.4484434475193777
   5%: -2.869513170510808
   10%: -2.571017574266393

결과 해석:
ADF 검정 통계량 (ADF Statistic): -1.4763584158714853
P-값 (p-value): 0.5451723991122808
=> 유의수준 5%에서 귀무가설을 기각할 수 없습니다. => 시계열 데이터는 안정적입니다.
",https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html
143,계절성 분해,시계열 데이터,계절성,식별,,"from statsmodels.tsa.seasonal import seasonal_decompose
seasonal_decompose(df[""차이분석""], model=""additive"")","import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.seasonal import seasonal_decompose

# 예시 데이터 생성
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=365)
data = np.random.randn(365).cumsum()
df = pd.DataFrame(data, index=dates, columns=['차이분석'])

# seasonal_decompose 함수를 사용하여 분해
result = seasonal_decompose(df[""차이분석""], model=""additive"")

# 분해된 요소들을 추출
trend = result.trend
seasonal = result.seasonal
residual = result.resid

# 시각화
plt.figure(figsize=(12, 8))
plt.subplot(411)
plt.plot(df[""차이분석""], label='Original')
plt.legend(loc='upper left')
plt.subplot(412)
plt.plot(trend, label='Trend')
plt.legend(loc='upper left')
plt.subplot(413)
plt.plot(seasonal, label='Seasonal')
plt.legend(loc='upper left')
plt.subplot(414)
plt.plot(residual, label='Residuals')
plt.legend(loc='upper left')
plt.tight_layout()
plt.show()
",-,https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.seasonal_decompose.html
144,SARIMAX,시계열 데이터,자기 회귀,통합,이동 평균,"sm.tsa.statespace.sarimax.SARIMAX(시계열 데이터, order=(7,0,0), seasonal_order=(1,0,1,12))","import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.statespace.sarimax import SARIMAX

# 예시 데이터 생성
np.random.seed(42)
dates = pd.date_range(start='2023-01-01', periods=365)
data = np.random.randn(365).cumsum()
df = pd.DataFrame(data, index=dates, columns=['시계열 데이터'])

# SARIMA 모델 생성
model = SARIMAX(df['시계열 데이터'], order=(7, 0, 0), seasonal_order=(1, 0, 1, 12))

# 모델 피팅 (학습)
results = model.fit()

# 모델 요약 정보 출력
print(results.summary())

# 예측 및 잔차 계산
df['Forecast'] = results.predict(start=300, end=365, dynamic=True)
df['Residuals'] = df['시계열 데이터'] - df['Forecast']

# 시각화
plt.figure(figsize=(12, 6))
plt.plot(df['시계열 데이터'], label='Original')
plt.plot(df['Forecast'], label='Forecast')
plt.legend()
plt.title('SARIMA 예측 및 원본 데이터')
plt.show()
",-,https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html
145,사분위수,quantile,데이터,4등분,분위수 값,"df[""컬럼명""].quantile([0.25, 0.5, 0.75])","import pandas as pd

# 예시 데이터 생성
data = {
    '컬럼명': [3, 6, 7, 8, 8, 10, 13, 15, 16, 20]
}

df = pd.DataFrame(data)

# 사분위수 계산
quantiles = df[""컬럼명""].quantile([0.25, 0.5, 0.75])

print(""사분위수:"")
print(quantiles)
","사분위수:
0.25     7.25
0.50     9.00
0.75    14.50
Name: 컬럼명, dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.quantile.html
146,상관관계,산점도,피어슨,상관계수,,"plt.scatter(데이터1, 데이터2), scipy.stats.pearsonr(데이터1, 데이터2)","import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

# 예시 데이터 생성
np.random.seed(0)
데이터1 = np.random.randn(100)
데이터2 = 2.0 * 데이터1 + 1.0 + np.random.randn(100)

# 산점도 그리기
plt.figure(figsize=(8, 6))
plt.scatter(데이터1, 데이터2, color='blue', label='데이터')
plt.title('데이터1 vs 데이터2 산점도')
plt.xlabel('데이터1')
plt.ylabel('데이터2')
plt.legend()
plt.grid(True)
plt.show()

# 피어슨 상관계수 계산
correlation, p_value = pearsonr(데이터1, 데이터2)
print(f""피어슨 상관계수: {correlation:.4f}, p-value: {p_value:.4f}"")
",,https://matplotlib.org/3.3.2/api/_as_gen/matplotlib.pyplot.scatter.html
147,원핫 인코딩,범주형 데이터,이진 형식,원핫,인코딩,sklearn.preprocessing.OneHotEncoder().fit_transform(데이터),"import numpy as np
from sklearn.preprocessing import OneHotEncoder

# 예시 데이터
data = np.array(['고양이', '개', '새', '고양이', '새']).reshape(-1, 1)

# OneHotEncoder 초기화
encoder = OneHotEncoder()

# 데이터에 대해 fit 및 transform 수행
data_encoded = encoder.fit_transform(data)

# 변환된 데이터 출력
print(""변환된 데이터:"")
print(data_encoded.toarray())

# 카테고리 출력
print(""\n카테고리:"")
print(encoder.categories_)

","변환된 데이터:
[[1. 0. 0.]
 [0. 1. 0.]
 [0. 0. 1.]
 [1. 0. 0.]
 [0. 0. 1.]]

카테고리:
[array(['개', '고양이', '새'], dtype=object)]

",https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html
148,describe,요약 통계,메서드,요약,통계,df.describe(),"import pandas as pd
import numpy as np

# 예시 데이터 생성
data = {
    'A': np.random.randn(100),
    'B': np.random.rand(100) * 100,
    'C': np.random.randint(1, 100, 100),
    'D': ['cat', 'dog', 'bird', 'cat', 'bird'] * 20
}

# 데이터프레임 생성
df = pd.DataFrame(data)

# describe() 메서드를 사용하여 요약 통계 정보 출력
summary = df.describe()

# 출력
print(summary)
","                A           B          C
count  100.000000  100.000000  100.00000
mean    -0.059232   48.379644   45.15000
std      0.956799   31.266062   29.72411
min     -2.772593    1.203622    1.00000
25%     -0.596565   23.779089   19.00000
50%     -0.075359   41.617162   40.00000
75%      0.538657   75.888226   69.50000
max      2.303917   99.440079   98.00000
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html
149,피처 스케일링,피처,기계 학습 모델,스케일링,변환,min_max_scaler = MinMaxScaler().fit(데이터),"import numpy as np
from sklearn.preprocessing import MinMaxScaler

# 예시 데이터 생성
data = np.array([[1, 2, 3],
                 [4, 5, 6],
                 [7, 8, 9]])

# MinMaxScaler 객체 생성 및 데이터에 fit_transform 적용
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data)

# 정규화된 데이터 출력
print(""정규화된 데이터:"")
print(scaled_data)

# 원본 데이터에 대한 스케일링 매개변수 출력
print(""\n스케일링 매개변수:"")
print(""최소값:"", scaler.data_min_)
print(""최대값:"", scaler.data_max_)
","정규화된 데이터:
[[0.  0.  0. ]
 [0.5 0.5 0.5]
 [1.  1.  1. ]]

스케일링 매개변수:
최소값: [1. 2. 3.]
최대값: [7. 8. 9.]
",https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler
150,데이터 분할,Scikit-learn,훈련,검증,테스트,"from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(독립변수, 종속변수, 테스트크기=0.2)","import numpy as np
from sklearn.model_selection import train_test_split

# 예시 데이터 생성
X = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]])
y = np.array([1, 2, 3])

# 데이터 분할 (train_test_split 함수 사용)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 분할된 데이터 출력
print(""X_train:\n"", X_train)
print(""\nX_test:\n"", X_test)
print(""\ny_train:"", y_train)
print(""\ny_test:"", y_test)
","X_train:
 [[4 5 6]
 [7 8 9]]

X_test:
 [[1 2 3]]

y_train: [2 3]

y_test: [1]
",https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
151,모델 평가,Scikit-learn,측정,성능,평가,"from sklearn.metrics import accuracy_score
score = accuracy_score(실제타겟값, 예측값)","from sklearn.metrics import accuracy_score

# 예시 데이터
y_true = [0, 1, 1, 0, 1, 1, 0, 1, 0]
y_pred = [0, 1, 0, 0, 1, 1, 1, 0, 0]

# 정확도 계산
score = accuracy_score(y_true, y_pred)

# 정확도 출력
print(f""Accuracy Score: {score}"")
","Accuracy Score: 0.6666666666666666
",https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html
152,데이터 임퓨팅,추정,임퓨팅,임퓨팅,,SimpleImputer(strategy='mean').fit_transform(x),"import numpy as np
from sklearn.impute import SimpleImputer

# 예시 데이터
X = np.array([[1, 2], [np.nan, 3], [7, 6]])

# SimpleImputer를 사용하여 누락된 값을 평균으로 채우기
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# 결과 출력
print(""Original Data:"")
print(X)
print(""\nImputed Data:"")
print(X_imputed)
","Original Data:
[[ 1.  2.]
 [nan  3.]
 [ 7.  6.]]

Imputed Data:
[[1. 2.]
 [4. 3.]
 [7. 6.]]
",https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html
153,ROC, AUC,이진 분류 모델,ROC 커브,수신기 조작 특성 곡선,"
실제레이블 = np.array([1, 1, 2, 2])
해당클래스에 속할 확률 = np.array([0.1, 0.4, 0.35, 0.8])
fpr, tpr, 임계값 = metrics.roc_curve(y, scores, 양성클래스=2","import numpy as np
from sklearn import metrics

# 예시 데이터
y = np.array([1, 1, 2, 2])
scores = np.array([0.1, 0.4, 0.35, 0.8])

# ROC 곡선 생성
fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)

# 결과 출력
print(""False Positive Rate (FPR):"", fpr)
print(""True Positive Rate (TPR):"", tpr)
print(""Thresholds:"", thresholds)
",,https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html
154,K-Means,클러스터,비지도 학습,K-Means 알고리즘,비지도 학습 알고리즘,"데이터포인트배열 = np.array([[1, 2], [1, 4], [1, 0],
              [10, 2], [10, 4], [10, 0]])
kmeans = KMeans(클러스터수=2, 랜덤시드=0, 초기중심값설정=""auto"").fit(X)","from sklearn.cluster import KMeans
import numpy as np

# 예시 데이터
X = np.array([[1, 2], [1, 4], [1, 0],
              [10, 2], [10, 4], [10, 0]])

# KMeans 모델 초기화 및 학습
kmeans = KMeans(n_clusters=2, random_state=0, n_init=10).fit(X)

# 클러스터링 결과
labels = kmeans.labels_
centers = kmeans.cluster_centers_

# 결과 출력
print(""Cluster labels:"", labels)
print(""Cluster centers:\n"", centers)
","Cluster labels: [0 0 0 1 1 1]
Cluster centers:
 [[ 1.  2.]
  [10.  2.]]
",https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
155,람다 함수,익명 함수,단일 표현식,,,lambda 파라미터: 표현식,"square = lambda x: x ** 2
print(square(5))
","25
",https://docs.python.org/3/reference/expressions.html#lambda
156,normaltest,Shapiro-Wilk,정규성,,,stats.normaltest(데이터),"import numpy as np
from scipy import stats

# 데이터 생성 (정규 분포를 따르지 않는 예시 데이터)
np.random.seed(0)
data = np.random.exponential(size=1000)

# 정규성 검정
statistic, p_value = stats.normaltest(data)

# 결과 출력
print(f""Normaltest statistic: {statistic}"")
print(f""P-value: {p_value}"")","Normaltest statistic: 452.7741994209466
P-value: 4.801001278930967e-99
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.normaltest.html
157,샘플 데이터,NumPy,라이브러리,샘플,,"np.random.randn(행수, 열수)","import numpy as np

# 난수 생성
rows = 2
cols = 3
data = np.random.randn(rows, cols)

# 생성된 데이터 출력
print(""Generated random data (normal distribution):"")
print(data)
","Generated random data (normal distribution):
[[-0.10169727  0.01927938  1.84959125]
 [-0.21416666 -0.49901664  0.02135122]]
",https://numpy.org/doc/1.26/reference/random/index.html
158,피벗 테이블,pivot_table,내장 함수,행/열 라벨,index/columns,"df.pivot_table(index='속성', columns='국가', values='수치')","import pandas as pd
import numpy as np

# Sample data
data = {
    '속성': ['A', 'B', 'A', 'B', 'A', 'B'],
    '국가': ['Korea', 'Korea', 'Japan', 'Japan', 'China', 'China'],
    '수치': [10, 20, 30, 40, 50, 60]
}

df = pd.DataFrame(data)

# Pivot table creation
pivot_df = df.pivot_table(index='속성', columns='국가', values='수치')

# Display the pivot table
print(""Pivot Table:"")
print(pivot_df)
","Pivot Table:
국가  China  Japan  Korea
속성                     
A    50.0   30.0   10.0
B    60.0   40.0   20.0
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html
159,corr,상관 행렬,pandas,상관,계산,"import pandas as pd
corr_matrix = df1.corr(df2)","import pandas as pd
import numpy as np

# Sample data
np.random.seed(0)
df1 = pd.DataFrame(np.random.randn(100, 4), columns=['A', 'B', 'C', 'D'])
df2 = pd.DataFrame(np.random.randn(100, 4), columns=['A', 'B', 'C', 'D'])

# Compute correlation matrix
corr_matrix = df1.corrwith(df2)

# Display correlation matrix
print(""Correlation Matrix:"")
print(corr_matrix)
","Correlation Matrix:
A   -0.220587
B   -0.094369
C   -0.082691
D    0.128346
dtype: float64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html
160,corrcoef,상관 행렬,triu,상관계수,임계값,"corr = np.corrcoef(데이터)  # 상관 행렬 계산
triu_corr = np.triu(corr)  # 상삼각 행렬 추출
high_corr_pairs = np.where(np.abs(triu_corr) > 임계값)","import numpy as np

# 샘플 데이터 생성 (5개 변수, 10개 샘플)
np.random.seed(1)
data = np.random.randn(10, 5)

# 상관 행렬 계산
corr = np.corrcoef(data, rowvar=False)  # rowvar=False: 각 열이 변수를 나타냄

# 상삼각 행렬 추출 (주대각선을 포함하지 않음)
triu_corr = np.triu(corr, k=1)  # k=1: 주대각선을 제외하고 추출

# 높은 상관 관계를 나타낼 임계값 설정
threshold = 0.8

# 절대값이 임계값보다 큰 원소의 인덱스 찾기
high_corr_pairs = np.where(np.abs(triu_corr) > threshold)

# 높은 상관 관계를 가진 변수 쌍의 인덱스 추출
pairs = [(i, j) for i, j in zip(high_corr_pairs[0], high_corr_pairs[1])]

# 높은 상관 관계를 가진 변수 쌍 출력
print(f""임계값 {threshold}을 넘는 높은 상관 관계를 가진 변수 쌍"")
for pair in pairs:
    var1 = pair[0]
    var2 = pair[1]
    correlation_coefficient = corr[var1, var2]
    print(f""변수 {var1}과(와) 변수 {var2}: 상관 계수 = {correlation_coefficient:.2f}"")","임계값 0.8을 넘는 높은 상관 관계를 가진 변수 쌍
변수 0과(와) 변수 1: 상관 계수 = -0.82
",https://numpy.org/doc/stable/reference/generated/numpy.corrcoef.html
161,Granger,시계열,인과 관계,grangercausalitytests,,"grangercausalitytests(시계열 데이터 1, 시계열 데이터 2)","import numpy as np
import pandas as pd
from statsmodels.tsa.stattools import grangercausalitytests

# 샘플 데이터 생성
np.random.seed(0)
n = 100
dates = pd.date_range(start='2023-01-01', periods=n, freq='D')
data = pd.DataFrame(np.random.randn(n, 2), columns=['시계열 데이터 1', '시계열 데이터 2'], index=dates)

# 그레인저 인과성 테스트 수행
max_lag = 2  # 최대 시차 설정
test = 'ssr_chi2test'  # 테스트 방법 설정

# 시계열 데이터 1이 데이터 2를 인과적으로 설명하는지 테스트
result = grangercausalitytests(data[['시계열 데이터 1', '시계열 데이터 2']], maxlag=max_lag, verbose=True)

# 테스트 결과 해석
for lag in range(1, max_lag + 1):
    p_value = result[lag][0][test][1]  # p-value
    print(f""시계열 데이터 1이 데이터 2를 {lag}일 이전에 인과적으로 설명하는지 테스트 (p-value): {p_value:.4f}"")

# 시계열 데이터 2가 데이터 1을 인과적으로 설명하는지 테스트
result = grangercausalitytests(data[['시계열 데이터 2', '시계열 데이터 1']], maxlag=max_lag, verbose=True)

# 테스트 결과 해석
for lag in range(1, max_lag + 1):
    p_value = result[lag][0][test][1]  # p-value
    print(f""시계열 데이터 2가 데이터 1을 {lag}일 이전에 인과적으로 설명하는지 테스트 (p-value): {p_value:.4f}"")

","Granger Causality
number of lags (no zero) 1
ssr based F test:         F=1.5118  , p=0.2219  , df_denom=96, df_num=1
ssr based chi2 test:   chi2=1.5590  , p=0.2118  , df=1
likelihood ratio test: chi2=1.5469  , p=0.2136  , df=1
parameter F test:         F=1.5118  , p=0.2219  , df_denom=96, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=1.1838  , p=0.3107  , df_denom=93, df_num=2
ssr based chi2 test:   chi2=2.4949  , p=0.2872  , df=2
likelihood ratio test: chi2=2.4637  , p=0.2918  , df=2
parameter F test:         F=1.1838  , p=0.3107  , df_denom=93, df_num=2
시계열 데이터 1이 데이터 2를 1일 이전에 인과적으로 설명하는지 테스트 (p-value): 0.2118
시계열 데이터 1이 데이터 2를 2일 이전에 인과적으로 설명하는지 테스트 (p-value): 0.2872

Granger Causality
number of lags (no zero) 1
ssr based F test:         F=1.1880  , p=0.2785  , df_denom=96, df_num=1
ssr based chi2 test:   chi2=1.2252  , p=0.2683  , df=1
likelihood ratio test: chi2=1.2177  , p=0.2698  , df=1
parameter F test:         F=1.1880  , p=0.2785  , df_denom=96, df_num=1

Granger Causality
number of lags (no zero) 2
ssr based F test:         F=0.8344  , p=0.4374  , df_denom=93, df_num=2
ssr based chi2 test:   chi2=1.7585  , p=0.4151  , df=2
likelihood ratio test: chi2=1.7429  , p=0.4183  , df=2
parameter F test:         F=0.8344  , p=0.4374  , df_denom=93, df_num=2
시계열 데이터 2가 데이터 1을 1일 이전에 인과적으로 설명하는지 테스트 (p-value): 0.2683
시계열 데이터 2가 데이터 1을 2일 이전에 인과적으로 설명하는지 테스트 (p-value): 0.415",https://www.statsmodels.org/stable/generated/statsmodels.tsa.stattools.grangercausalitytests.html
162,빈도표,value_counts,pandas,생성,,"빈도표 = 데이터프레임['컬럼'].value_counts()
print(빈도표)","import pandas as pd

# 데이터프레임 예시 데이터 생성
data = {
    '컬럼': ['A', 'B', 'A', 'C', 'A', 'B', 'B', 'C', 'A', 'B', 'A']
}
df = pd.DataFrame(data)

# 빈도표 생성
빈도표 = df['컬럼'].value_counts()

# 빈도표 출력
print(빈도표)","컬럼
A    5
B    4
C    2
Name: count, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.Series.value_counts.html
163,결정 트리,DecisionTreeClassifier,sklearn,결정,트리,"from sklearn.tree import DecisionTreeClassifier

# 결정 트리 생성
모형 = DecisionTreeClassifier().fit(특징, 타깃)

# 결과 출력
print(모형.tree_)","from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.datasets import load_iris

# 데이터 불러오기
iris = load_iris()
X = iris.data
y = iris.target

# 결정 트리 생성
모형 = DecisionTreeClassifier().fit(X, y)

# 결정 트리 구조를 텍스트로 변환하여 출력
트리_텍스트 = export_text(모형, feature_names=iris.feature_names)
print(트리_텍스트)","|--- petal length (cm) <= 2.45
|   |--- class: 0
|--- petal length (cm) >  2.45
|   |--- petal width (cm) <= 1.75
|   |   |--- petal length (cm) <= 4.95
|   |   |   |--- petal width (cm) <= 1.65
|   |   |   |   |--- class: 1
|   |   |   |--- petal width (cm) >  1.65
|   |   |   |   |--- class: 2
|   |   |--- petal length (cm) >  4.95
|   |   |   |--- petal width (cm) <= 1.55
|   |   |   |   |--- class: 2
|   |   |   |--- petal width (cm) >  1.55
|   |   |   |   |--- petal length (cm) <= 5.45
|   |   |   |   |   |--- class: 1
|   |   |   |   |--- petal length (cm) >  5.45
|   |   |   |   |   |--- class: 2
|   |--- petal width (cm) >  1.75
|   |   |--- petal length (cm) <= 4.85
|   |   |   |--- sepal width (cm) <= 3.10
|   |   |   |   |--- class: 2
|   |   |   |--- sepal width (cm) >  3.10
|   |   |   |   |--- class: 1
|   |   |--- petal length (cm) >  4.85
|   |   |   |--- class: 2

",https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html
164,부트스트랩,bootstrap,SciPy,,,"from scipy.stats import bootstrap
bootstrap_mean(데이터, 부트스트랩 샘플 수=1000, 신뢰구간=0.05)","import numpy as np
import scipy.stats

# 예시 데이터 생성
np.random.seed(0)
data = np.random.normal(loc=0, scale=1, size=100)

# 부트스트랩 함수 정의
def bootstrap_mean(data, num_samples=1000, alpha=0.05):
    n = len(data)
    indices = np.random.randint(0, n, (num_samples, n))
    samples = data[indices]
    sample_means = np.mean(samples, axis=1)
    mean = np.mean(data)
    lower_ci, upper_ci = np.percentile(sample_means, [100 * alpha / 2, 100 * (1 - alpha / 2)])
    return mean, lower_ci, upper_ci

# 부트스트랩 함수를 이용한 평균과 신뢰 구간 계산
mean, lower_ci, upper_ci = bootstrap_mean(data, num_samples=1000, alpha=0.05)

# 결과 출력
print(f""Mean: {mean}"")
print(f""95% Confidence interval of the mean: [{lower_ci}, {upper_ci}]"")

","Mean: 0.059808015534485
95% Confidence interval of the mean: [-0.13559954954754985, 0.2648017467336251]
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bootstrap.html
165,백분위수 회귀,mstats_quantiles,SciPy,함수,회귀,"from scipy.stats import mstats_quantiles
mstats_quantiles(데이터)","from scipy.stats import mstats_quantiles
import numpy as np

# 데이터 생성 예시
data = np.random.normal(loc=0, scale=1, size=100)

# mstats_quantiles를 이용한 분위수 계산
quantiles = mstats_quantiles(data, prob=[0.25, 0.5, 0.75])

# 결과 출력
print(""25th percentile (Q1):"", quantiles[0])
print(""50th percentile (median, Q2):"", quantiles[1])
print(""75th percentile (Q3):"", quantiles[2])","25th percentile (Q1): -0.5131628855293403
50th percentile (median, Q2): -0.05835365479594458
75th percentile (Q3): 0.7491867060223641",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mstats.hdquantiles.html
166,하이퍼파라미터,GridSearchCV,성능,최적화,조정,"param_grid = {'C': [1, 10, 100], 'kernel': ['linear', 'rbf']}
grid_search = sklearn.model_selection.GridSearchCV(model, param_grid, cv=5)
grid_search.fit(X, y)","import sklearn.model_selection
from sklearn.datasets import make_classification
from sklearn.svm import SVC

# 예제 데이터 생성
X, y = make_classification(n_samples=1000, n_features=20, random_state=42)

# SVM 모델 초기화
model = SVC()

# 탐색할 매개변수 그리드 정의
param_grid = {'C': [1, 10, 100], 'kernel': ['linear', 'rbf']}

# GridSearchCV 객체 초기화
grid_search = sklearn.model_selection.GridSearchCV(model, param_grid, cv=5)

# GridSearchCV 수행
grid_search.fit(X, y)

# 최적의 매개변수 및 정확도 출력
print(""Best parameters found: "", grid_search.best_params_)
print(""Best cross-validation score: {:.2f}"".format(grid_search.best_score_))

# 테스트 데이터를 사용하지 않고 최종 모델 평가
best_model = grid_search.best_estimator_
score = best_model.score(X, y)
print(""Final model score on train data: {:.2f}"".format(score))
","Best parameters found:  {'C': 10, 'kernel': 'linear'}
Best cross-validation score: 0.87
Final model score on train data: 0.88
",https://scikit-learn.org/stable/modules/grid_search.html
167,Pandas,중복된,제거,duplicates,,"데이터프레임.drop_duplicates(subset=""열 이름"")","import pandas as pd

# 예제 데이터 생성
data = {
    '이름': ['홍길동', '이순신', '홍길동', '김유신', '홍길동'],
    '나이': [30, 40, 30, 25, 30],
    '도시': ['서울', '부산', '서울', '대전', '서울']
}

df = pd.DataFrame(data)

# 중복된 '이름' 열을 기준으로 중복 제거
df_unique = df.drop_duplicates(subset='이름')

print(""원본 데이터프레임:"")
print(df)
print(""\n중복 제거 후 데이터프레임:"")
print(df_unique)
","    이름  나이   도시
0  홍길동  30  서울
1  이순신  40  부산
2  홍길동  30  서울
3  김유신  25  대전
4  홍길동  30  서울
",https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html
168,계절적,차분,계수,seasonal_decompose,,"from statsmodels.tsa.seasonal import seasonal_decompose
result = seasonal_decompose(시계열_데이터, model=""additive"")
print(result.seasonal)","# 예제 시계열 데이터 생성
np.random.seed(0)
date_range = pd.date_range(start='2020-01-01', periods=100, freq='D')
trend = np.linspace(0, 1, 100)
seasonal = np.sin(np.linspace(0, 2 * np.pi, 100)) * 0.1
residual = np.random.normal(scale=0.1, size=100)
ts_data = trend + seasonal + residual

# 데이터프레임 생성
df = pd.DataFrame({'date': date_range, 'value': ts_data})
df.set_index('date', inplace=True)

# 시계열 분해
result = seasonal_decompose(df['value'], model='additive')

# 결과 출력
print(""계절성 요소:"")
print(result.seasonal.head(10))  # 상위 10개 값 출력

# 결과 시각화
result.plot()
plt.show()","date
2020-01-01    0.000000
2020-01-02    0.006342
2020-01-03    0.012659
2020-01-04    0.018926
2020-01-05    0.025114
2020-01-06    0.031188
2020-01-07    0.037120
2020-01-08    0.042874
2020-01-09    0.048418
2020-01-10    0.053718
Name: seasonal, dtype: float64
",https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html
169,정밀도,재현율,양성 클래스,예측,,"from sklearn.metrics import precision_score, recall_score
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)","from sklearn.metrics import precision_score, recall_score

# 실제 값 (정답)
y_true = [0, 1, 1, 1, 0, 1, 0, 0, 1, 0]

# 예측 값 (모델의 예측)
y_pred = [0, 1, 0, 1, 0, 1, 0, 0, 1, 1]

# 정밀도 (Precision) 계산
precision = precision_score(y_true, y_pred)

# 재현율 (Recall) 계산
recall = recall_score(y_true, y_pred)

# 결과 출력
print(f""정밀도 (Precision): {precision}"")
print(f""재현율 (Recall): {recall}"")
","정밀도 (Precision): 0.75
재현율 (Recall): 0.75
",https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html
170,결측값,평균값,중앙값,대체,,"# 결측값 제거
데이터프레임.dropna()

# 평균값으로 대체
데이터프레임.fillna(데이터프레임.mean())

# 중앙값으로 대체
데이터프레임.fillna(데이터프레임.median())","import pandas as pd
import numpy as np

# 예제 데이터프레임 생성
data = {
    'A': [1, 2, np.nan, 4, 5],
    'B': [5, np.nan, np.nan, 8, 10],
    'C': [np.nan, 1, 2, 3, 4]
}
df = pd.DataFrame(data)

print(""원본 데이터프레임:"")
print(df)

# 1. 결측값 제거
df_dropped = df.dropna()

# 2. 결측값을 열의 평균값으로 대체
df_filled_mean = df.fillna(df.mean())

# 3. 결측값을 열의 중앙값으로 대체
df_filled_median = df.fillna(df.median())

# 결과 출력
print(""\n결측값 제거 후 데이터프레임:"")
print(df_dropped)

print(""\n결측값을 평균값으로 대체한 데이터프레임:"")
print(df_filled_mean)

print(""\n결측값을 중앙값으로 대체한 데이터프레임:"")
print(df_filled_median)
","# 결측값 제거
     A     B    C
3  4.0   8.0  3.0
4  5.0  10.0  4.0

# 결측값을 평균값으로 대체
          A          B    C
0  1.000000   5.000000  2.5
1  2.000000   7.666667  1.0
2  3.000000   7.666667  2.0
3  4.000000   8.000000  3.0
4  5.000000  10.000000  4.0

# 결측값을 중앙값으로 대체
     A     B    C
0  1.0   5.0  2.5
1  2.0   8.0  1.0
2  4.0   8.0  2.0
3  4.0   8.0  3.0
4  5.0  10.0  4.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html
171,균형,샘플,과적합,과샘플링,과소샘플링,"# 과샘플링
from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=0)
X_resampled, y_resampled = ros.fit_resample(X, y)

# 과소샘플링
from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler(random_state=0)
X_resampled, y_resampled = rus.fit_resample(X, y)","# 가상의 데이터 생성
np.random.seed(0)
# 다수 클래스
X_majority = np.random.normal(loc=0, scale=1, size=(1000, 2))
y_majority = np.zeros(1000)
# 소수 클래스
X_minority = np.random.normal(loc=2, scale=1, size=(100, 2))
y_minority = np.ones(100)

# 과샘플링
ros = RandomOverSampler(random_state=0)
X_resampled_over, y_resampled_over = ros.fit_resample(np.vstack((X_majority, X_minority)), np.hstack((y_majority, y_minority)))

# 과소샘플링
rus = RandomUnderSampler(random_state=0)
X_resampled_under, y_resampled_under = rus.fit_resample(np.vstack((X_majority, X_minority)), np.hstack((y_majority, y_minority)))

# 결과 출력
print(""과샘플링 후 클래스 레이블 분포:"", np.bincount(y_resampled_over))
print(""과소샘플링 후 클래스 레이블 분포:"", np.bincount(y_resampled_under))","과샘플링 후 클래스 레이블 분포: [1000 1000]
과소샘플링 후 클래스 레이블 분포: [100 100]
",https://imbalanced-learn.org/stable/user_guide.html#user-guide
172,이상치 감지,Z-점수,IQR,사분위 범위,,"# Z-점수
from scipy.stats import zscore
z_scores = np.abs(zscore(X))
outliers = np.where(z_scores > 3)

# IQR
iqr = np.percentile(X, 75) - np.percentile(X, 25)
lower_bound = np.percentile(X, 25) - (iqr * 1.5)
upper_bound = np.percentile(X, 75) + (iqr * 1.5)
outliers = np.where((X < lower_bound) | (X > upper_bound))","import numpy as np
from scipy.stats import zscore

# 가상의 데이터 생성
np.random.seed(0)
X = np.random.normal(loc=0, scale=1, size=100)

# Z-점수를 사용하여 이상치 탐지
z_scores = np.abs(zscore(X))
outliers_zscore = np.where(z_scores > 3)

# IQR을 사용하여 이상치 탐지
Q1 = np.percentile(X, 25)
Q3 = np.percentile(X, 75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR
outliers_iqr = np.where((X < lower_bound) | (X > upper_bound))

print(""Z-점수를 사용한 이상치 탐지:"")
print(""이상치 인덱스:"", outliers_zscore[0])
print(""\nIQR을 사용한 이상치 탐지:"")
print(""이상치 인덱스:"", outliers_iqr[0])
","Z-점수를 사용한 이상치 탐지:
이상치 인덱스: []

IQR을 사용한 이상치 탐지:
이상치 인덱스: [13 15 83 93 95]
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.zscore.html
173,로그 변환,Box-Cox,데이터 변환,분포,특성,"# 로그 변환
데이터프레임[""컬럼명""] = np.log(데이터프레임[""컬럼명""])

# Box-Cox 변환
from scipy import stats
데이터프레임[""컬럼명""], _ = stats.boxcox(데이터프레임[""컬럼명""])","import pandas as pd
import numpy as np
from scipy import stats

# 가상의 데이터프레임 생성
data = {
    'A': [1, 2, 3, 4, 5],
    'B': [10, 20, 30, 40, 50],
}
df = pd.DataFrame(data)

# 로그 변환
df['A_log'] = np.log(df['A'])

# Box-Cox 변환
df['B_boxcox'], _ = stats.boxcox(df['B'])

# 결과 출력
print(""로그 변환 후 데이터프레임:"")
print(df[['A', 'A_log']])

print(""\nBox-Cox 변환 후 데이터프레임:"")
print(df[['B', 'B_boxcox']])
","로그 변환 후 데이터프레임:
   A     A_log
0  1  0.000000
1  2  0.693147
2  3  1.098612
3  4  1.386294
4  5  1.609438

Box-Cox 변환 후 데이터프레임:
    B   B_boxcox
0  10  23.207037
1  20  27.445885
2  30  30.734427
3  40  33.927285
4  50  36.877980
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.boxcox.html
174,SVM 모델,파라미터,커널,규제화,감마,"from sklearn.svm import SVC

# SVM 모델 생성
svm = SVC(kernel='rbf', C=1.0, gamma=0.1)

# 모델 훈련
svm.fit(X_train, y_train)","from sklearn.svm import SVC

# 가상의 훈련 데이터 생성 (임의의 예시 데이터)
X_train = [[0, 0], [1, 1]]
y_train = [0, 1]

# SVM 모델 생성
svm = SVC(kernel='rbf', C=1.0, gamma=0.1)

# 모델 훈련
svm.fit(X_train, y_train)",,https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html
175,텍스트 토큰화,문자열,토큰,기계 학습 모델,,tokenizer = Tokenizer(num_words=1000),"from keras.preprocessing.text import Tokenizer

# 가상의 텍스트 데이터 생성
texts = [
    'This is a sample text for tokenization.',
    'Another sample text for testing purposes.',
    'Yet another example for demonstration.'
]

# 토큰화를 위한 Tokenizer 객체 생성
tokenizer = Tokenizer(num_words=1000)

# 텍스트 데이터에 대해 토큰화 수행
tokenizer.fit_on_texts(texts)

# 텍스트 데이터를 시퀀스 데이터로 변환
sequences = tokenizer.texts_to_sequences(texts)

# 결과 출력
print(""텍스트 시퀀스:"")
print(sequences)
","텍스트 시퀀스:
[[1, 2, 3, 4, 5, 6], [7, 2, 3, 4, 8], [9, 10, 11, 12]]
",https://keras.io/api/preprocessing/text/
176,random,randrange,난수,,,"random.randrange(시작값, 끝값)","import random

# 시작값과 끝값을 설정
start = 1
end = 10

# 임의의 정수 생성
random_number = random.randrange(start, end)

# 결과 출력
print(""임의의 정수:"", random_number)
",임의의 정수: 5,https://docs.python.org/3/library/random.html#random.randrange
177,통계적 유의성,연구 가설,지지,무작위성,,statsmodels.stats.contingency_tables.chi2_contingency(교차표),"import numpy as np
from scipy.stats import chi2_contingency

# 가상의 교차표 생성
observed = np.array([[10, 20, 30],
                     [6,  9,  17]])

# 카이제곱 독립성 검정 수행
chi2_stat, p_val, dof, expected = chi2_contingency(observed)

# 결과 출력
print(""카이제곱 통계량:"", chi2_stat)
print(""p-value:"", p_val)
print(""자유도:"", dof)
print(""기대값:"")
print(expected)
","카이제곱 통계량: 0.14750716852540268
p-value: 0.9295702832495743
자유도: 2
기대값:
[[10.34482759 19.48275862 29.17241379]
 [ 5.65517241 10.51724138 15.82758621]]
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html
178,가설 설정,데이터 수집,p-값,통계량 계산,귀무가설,"scipy.stats.mannwhitneyu(데이터1, 데이터2)","from scipy.stats import mannwhitneyu

# 가상의 데이터 생성
data1 = [12, 15, 17, 20, 22]
data2 = [9, 11, 14, 18, 21]

# Mann-Whitney U 검정 수행
statistic, p_value = mannwhitneyu(data1, data2)

# 결과 출력
print(""Mann-Whitney U 통계량:"", statistic)
print(""p-value:"", p_value)
","Mann-Whitney U 통계량: 11.0
p-value: 0.4139944027047587
",https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html
179,귀무 가설,대립 가설,검증,상반,,"귀무 가설: mean1 = mean2
대립 가설: mean1 != mean2","group1 = [12, 15, 17, 20, 22]
group2 = [9, 11, 14, 18, 21]

# 독립표본 t-검정 수행
statistic, p_value = ttest_ind(group1, group2)

# 결과 출력
print(""t-검정 통계량:"", statistic)
print(""p-value:"", p_value)

# 유의수준(alpha) 설정
alpha = 0.05

# p-value와 유의수준 비교
if p_value < alpha:
    print(""유의수준 {}에서 검정 결과: 귀무가설 기각, 두 그룹의 평균은 서로 다릅니다."".format(alpha))
else:
    print(""유의수준 {}에서 검정 결과: 귀무가설 채택, 두 그룹의 평균은 서로 같습니다."".format(alpha))
","t-검정 통계량: 0.28970903186963254
p-value: 0.7807144604255732
유의수준 0.05에서 검정 결과: 귀무가설 채택, 두 그룹의 평균은 서로 같습니다.
","https://en.wikipedia.org/wiki/Null_hypothesis_and_alternative_hypothesis
"
180,조기 종료 기법,과적합,모니터링,훈련,성능,from sklearn.model_selection import EarlyStopping,"# 데이터 로드
iris = load_iris()
X, y = iris.data, iris.target

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 파이프라인 생성
pipeline = make_pipeline(StandardScaler(), SVC())

# 조기 종료를 위한 EarlyStopping 콜백 정의
early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True)

# 교차 검증
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# 모델 훈련 및 검증
scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring='accuracy', fit_params={'callbacks': [early_stopping]})

# 결과 출력
print(""교차 검증 정확도:"", scores.mean())",,https://scikit-learn.org/stable/auto_examples/ensemble/plot_gradient_boosting_early_stopping.html
181,모델.예측(),독립변수, 회귀 모델,예측,,예측값 = model.predict(독립변수의 값),"iris = load_iris()
X, y = iris.data, iris.target

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 데이터 전처리 (표준화)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# SVM 모델 생성 및 훈련
svm = SVC(kernel='linear', random_state=42)
svm.fit(X_train_scaled, y_train)

# 예측 수행
y_pred = svm.predict(X_test_scaled)

# 예측 결과 출력
print(""예측값:"", y_pred)

# 정확도 계산
accuracy = accuracy_score(y_test, y_pred)
print(""정확도:"", accuracy)
",,https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict
182,다중 공선성,모델의 계수,불안정,예측 성능,저하,sklearn.preprocessing.VarianceThreshold(threshold=0.5),"# 데이터 로드
iris = load_iris()
X, y = iris.data, iris.target

# 데이터 분할
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 데이터 표준화
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# VarianceThreshold 변환기 적용
selector = VarianceThreshold(threshold=0.5)
X_train_selected = selector.fit_transform(X_train_scaled)

# 선택된 특성의 인덱스 출력
selected_features = np.array(iris.feature_names)[selector.get_support()]
print(""선택된 특성:"", selected_features)","선택된 특성: ['sepal length (cm)' 'sepal width (cm)']
",https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html#sklearn.feature_selection.VarianceThreshold
183,차이분석,음수,정규성화,정수,,"model = Seasonal(시계열, order=(1,1,1,12))","np.random.seed(0)
n = 100
time = np.arange(n)
seasonal_component = np.sin(2 * np.pi * time / 12)
trend_component = 0.5 * time
noise = np.random.normal(0, 1, size=n)
series = 10 + trend_component + seasonal_component + noise

# Seasonal ARIMA 모델 생성
from statsmodels.tsa.statespace.sarimax import SARIMAX
model = SARIMAX(series, order=(1,1,1), seasonal_order=(1,1,1,12))

# 모델 피팅
result = model.fit()

# 결과 출력
print(result.summary())
","                                 Statespace Model Results                                 
=============================
Dep. Variable:                                  y   No. Observations:                  100
Model:             SARIMAX(1, 1, 1)x(1, 1, 1, 12)   Log Likelihood                -143.778
Date:                            Thu, 10 Jun 2024   AIC                            297.557
Time:                                    11:30:00   BIC                            309.044
Sample:                                         0   HQIC                           302.128
                                             - 100                                         
Covariance Type:                              opg                                         
==============================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
ar.L1          0.0330      0.283      0.117      0.907      -0.521       0.587
ma.L1         -0.8823      0.154     -5.730      0.000      -1.184      -0.580
ar.S.L12      -0.5370      0.358     -1.501      0.133      -1.238       0.164
ma.S.L12      -0.2659      0.417     -0.637      0.524      -1.082       0.550
sigma2         1.0534      0.211      4.992      0.000       0.640       1.467
===================================================================================
Ljung-Box (Q):                       45.43   Jarque-Bera (JB):                 0.42
Prob(Q):                              0.25   Prob(JB):                         0.81
Heteroskedasticity (H):               0.87   Skew:                             0.13
Prob(H) (two-sided):                  0.67   Kurtosis:                         2.87
===================================================================================

Warnings:
[1] Covariance matrix calculated using the outer product of gradients (complex-step).
",https://www.statsmodels.org/stable/generated/statsmodels.tsa.statespace.sarimax.SARIMAX.html
184,pivot,변환,행을 열로 변환,,,"df.pivot(index='컬럼명1', columns='컬럼명2')","import pandas as pd

# 예시 데이터프레임 생성
data = {
    'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'baz'],
    'B': ['one', 'one', 'two', 'two', 'one', 'two'],
    'C': [1, 2, 3, 4, 5, 6]
}
df = pd.DataFrame(data)

# pivot을 이용하여 데이터프레임 재구성
pivot_df = df.pivot(index='A', columns='B', values='C')

# 결과 출력
print(""재구성된 데이터프레임:"")
print(pivot_df)
","재구성된 데이터프레임:
B    one  two
A           
bar  5.0  4.0
baz  NaN  6.0
foo  1.0  3.0
",https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pivot.html
185,groupby,연산 함수,그룹화,동시에 수행,,"df.groupby('컬럼명').agg({'컬럼명1': 'mean', '컬럼명2': 'max'}) # 컬럼명 열을 기준으로 평균과 최댓값","import pandas as pd

# 예시 데이터프레임 생성
data = {
    'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'baz'],
    'B': ['one', 'one', 'two', 'two', 'one', 'two'],
    'C': [1, 2, 3, 4, 5, 6],
    'D': [7, 8, 9, 10, 11, 12]
}
df = pd.DataFrame(data)

# 컬럼명을 기준으로 그룹화하여 집계
result = df.groupby('A').agg({'C': 'mean', 'D': 'max'})

# 결과 출력
print(""컬럼명을 기준으로 평균과 최댓값 집계:"")
print(result)
","컬럼명을 기준으로 평균과 최댓값 집계:
     C   D
A         
bar  4  11
baz  6  12
foo  2   9
",https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.GroupBy.agg.html
186,pivot_table,groupby,체이닝,그룹화,피벗 형식,"df.groupby('컬럼명1').pivot_table(index='컬럼명2', columns='컬럼명3', values='컬럼명4') # 컬럼명1 기준 그룹화, 컬럼명2 인덱스, 컬럼명3 컬럼, 컬럼명4 값으로 피벗","data = {
    'A': ['foo', 'foo', 'foo', 'bar', 'bar', 'baz'],
    'B': ['one', 'one', 'two', 'two', 'one', 'two'],
    'C': ['x', 'y', 'x', 'y', 'x', 'y'],
    'D': [1, 2, 3, 4, 5, 6]
}
df = pd.DataFrame(data)

# 컬럼명1을 기준으로 그룹화하여 피벗 테이블 생성
pivot_df = df.groupby('A').pivot_table(index='B', columns='C', values='D')

# 결과 출력
print(""컬럼명1을 기준으로 그룹화하고 피벗 테이블 생성:"")
print(pivot_df)
","컬럼명1을 기준으로 그룹화하고 피벗 테이블 생성:
C    x  y
A        
bar  5  4
baz  6  6
foo  2  2
",https://pandas.pydata.org/docs/reference/api/pandas.pivot_table.html
187,데이터 정규화,일관된 범위,데이터 간의 비교,훈련,용이,sklearn.preprocessing.StandardScaler().fit_transform(데이터),"from sklearn.preprocessing import StandardScaler
import numpy as np

# 예시 데이터 생성
data = np.array([[1, 2], [3, 4], [5, 6]])

# StandardScaler를 사용하여 데이터 표준화
scaler = StandardScaler()
scaled_data = scaler.fit_transform(data)

# 결과 출력
print(""표준화된 데이터:"")
print(scaled_data)
","표준화된 데이터:
[[-1.22474487 -1.22474487]
 [ 0.          0.        ]
 [ 1.22474487  1.22474487]]
",https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html
188,커널 밀도 추정,밀도,비모수적,이상치,식별,"from sklearn.neighbors import KernelDensity
kde = KernelDensity(kernel='gaussian', bandwidth=0.5)
kde.fit(X)","from sklearn.neighbors import KernelDensity
import numpy as np

# 가상의 데이터 생성
np.random.seed(0)
X = np.random.normal(0, 1, size=100).reshape(-1, 1)

# KernelDensity 모델 생성 및 피팅
kde = KernelDensity(kernel='gaussian', bandwidth=0.5)
kde.fit(X)

# 결과 출력
print(""KernelDensity 모델 피팅 완료."")
",,https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KernelDensity.html
189,대규모 데이터,빅데이터,프레임워크,분산 처리,병렬 처리,"from pyspark import SparkContext
sc = SparkContext.getOrCreate()","from pyspark import SparkContext

# SparkContext 생성
sc = SparkContext.getOrCreate()

# 결과 출력
print(""SparkContext가 성공적으로 생성되었습니다."")
",,https://spark.apache.org/docs/latest/index.html
190,특징 중요도,기여하는 정도,랜덤 포레스트,,,"from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(); model.fit(X, y)
feature_importances = model.feature_importances_","# 예시 데이터 생성
np.random.seed(0)
X = np.random.rand(100, 10)  # 100개의 샘플과 10개의 특성
y = np.random.randint(0, 2, size=100)  # 이진 분류 타깃

# RandomForestClassifier 모델 생성 및 훈련
model = RandomForestClassifier()
model.fit(X, y)

# 특성 중요도 추정
feature_importances = model.feature_importances_

# 결과 출력
print(""특성 중요도:"")
print(feature_importances)","특성 중요도:
[0.10442248 0.04797151 0.1149741  0.07101048 0.06092204 0.08944214
 0.11515749 0.11001581 0.10103675 0.0850472 ]
",https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#randomforestclassifier
191,k-means,DBSCAN,클러스터링,유사한 그룹,분류,"from sklearn.cluster import Kmeans
KMeans(n_clusters=3).fit(데이터)","from sklearn.cluster import KMeans
import numpy as np

# 예시 데이터 생성
np.random.seed(0)
X = np.random.rand(100, 2)  # 100개의 샘플과 2개의 특성

# KMeans 모델 생성 및 피팅
kmeans = KMeans(n_clusters=3)
kmeans.fit(X)

# 클러스터 할당 결과
labels = kmeans.labels_

# 클러스터 중심
centers = kmeans.cluster_centers_
",,https://scikit-learn.org/stable/modules/clustering.html
192,go.Scatter3d, 3차원 산포 플롯,3차원 데이터,시각화,,"go.Scatter3d(x=x, y=y, z=z)","import plotly.graph_objects as go

# 예시 데이터 생성
import numpy as np
np.random.seed(0)
x = np.random.rand(100)
y = np.random.rand(100)
z = np.random.rand(100)

# 3D 산점도 그리기
fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers')])
fig.show()
",,https://plotly.com/python-api-reference/
193,회귀 모델,과적합,L1,L2,,1,"from sklearn.svm import SVC
import numpy as np

# 예시 데이터 생성
np.random.seed(0)
X = np.random.rand(100, 2)  # 100개의 샘플과 2개의 특성
y = np.random.randint(0, 2, size=100)  # 이진 분류 타깃

# SVC 모델 생성
model = SVC(kernel='linear', C=1.0)

# C 하이퍼파라미터 변경
model.set_params(C=0.1)

# 변경된 하이퍼파라미터 확인
print(""변경된 모델 파라미터:"", model.get_params())
","변경된 모델 파라미터: 
{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}
","https://scikit-learn.org/stable/modules/linear_model.html
"
194,MSE,R2,RMSE,평균 제곱 오차,루트 평균 제곱 오차,"from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
mse = mean_squared_error(실제_값, 예측_값)
r2 = r2_score(실제_값, 예측_값)
mae = mean_absolute_error(실제_값, 예측_값)","from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# 예시 데이터
실제_값 = [3, -0.5, 2, 7]
예측_값 = [2.5, 0.0, 2, 8]

# 평균 제곱 오차(MSE) 계산
mse = mean_squared_error(실제_값, 예측_값)

# 결정 계수(R^2) 계산
r2 = r2_score(실제_값, 예측_값)

# 평균 절대 오차(MAE) 계산
mae = mean_absolute_error(실제_값, 예측_값)

# 결과 출력
print(""평균 제곱 오차(MSE):"", mse)
print(""결정 계수(R^2):"", r2)
print(""평균 절대 오차(MAE):"", mae)
","평균 제곱 오차(MSE): 0.375
결정 계수(R^2): 0.9486081370449679
평균 절대 오차(MAE): 0.5
",https://scikit-learn.org/stable/modules/model_evaluation.html
195,matplotlib,회귀 모델,시각화,,,"import matplotlib.pyplot as plt
plt.scatter(데이터, 타깃)
plt.plot(데이터, reg.predict(데이터))
plt.show()","import matplotlib.pyplot as plt

# 데이터와 타깃 생성 (예시)
데이터 = [1, 2, 3, 4, 5]
타깃 = [2, 3, 4, 5, 6]

# 선형 회귀 모델의 예측값 생성 (예시)
예측값 = [1.5, 2.5, 3.5, 4.5, 5.5]

# 산점도와 회귀선 그리기
plt.scatter(데이터, 타깃, label='실제 값')
plt.plot(데이터, 예측값, color='red', label='선형 회귀 예측')
plt.xlabel('데이터')
plt.ylabel('타깃')
plt.title('선형 회귀 예측 결과')
plt.legend()
plt.show()
",,https://matplotlib.org/stable/api/
196,교차 검증,객관적,성능,과대적합,방지,"model = LinearRegression()
scores = cross_val_score(model, x, y, cv=5)","# 예시 데이터 생성
np.random.seed(0)
x = np.random.rand(100, 2)  # 100개의 샘플과 2개의 특성
y = np.random.rand(100)  # 예측할 타깃

# 선형 회귀 모델 생성
model = LinearRegression()

# 교차 검증 수행
scores = cross_val_score(model, x, y, cv=5)

# 교차 검증 결과 출력
print(""교차 검증 점수:"", scores)
print(""평균 교차 검증 점수:"", np.mean(scores))
","교차 검증 점수: [0.38296148 0.42852686 0.28911729 0.29678397 0.33189915]
평균 교차 검증 점수: 0.3454575501803055
",https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html
197,주성분 분석,데이터의 차원,상관관계,예측 변수,제거,"pca = PCA(n_components=2)
x_transformed = pca.fit_transform(x)
model = LinearRegression()
model.fit(x_transformed, y)","# 예시 데이터 생성
np.random.seed(0)
x = np.random.rand(100, 10)  # 100개의 샘플과 10개의 특성
y = np.random.rand(100)  # 예측할 타깃

# PCA를 사용하여 차원 축소
pca = PCA(n_components=2)
x_transformed = pca.fit_transform(x)

# 선형 회귀 모델 생성 및 훈련
model = LinearRegression()
model.fit(x_transformed, y)

# 훈련된 모델의 계수와 절편 확인
print(""훈련된 모델의 계수:"", model.coef_)
print(""훈련된 모델의 절편:"", model.intercept_)
","훈련된 모델의 계수: [ 0.09435132 -0.00599305]
훈련된 모델의 절편: 0.4863517065634688
",https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html
198,릿지,L2,가중치,라쏘,L1,"ridge = LinearRegression(alpha=1)
lasso = LinearRegression(alpha=1, selection='cyclic')","from sklearn.linear_model import Ridge, Lasso
import numpy as np

# 예시 데이터 생성
np.random.seed(0)
X = np.random.rand(100, 10)  # 100개의 샘플과 10개의 특성
y = np.random.rand(100)  # 예측할 타깃

# Ridge 회귀 모델 생성 및 훈련
ridge = Ridge(alpha=1)
ridge.fit(X, y)

# Lasso 회귀 모델 생성 및 훈련
lasso = Lasso(alpha=1, selection='cyclic')
lasso.fit(X, y)
",,https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_and_elasticnet.html#lasso
199,시계열 데이터,회귀 분석,시간적 의존성,,,from statsmodels.tsa.api import SimpleExpSmoothing,"from statsmodels.tsa.api import SimpleExpSmoothing
import numpy as np

# 예시 데이터 생성
np.random.seed(0)
data = np.random.rand(100)

# SimpleExpSmoothing 모델 생성 및 피팅
model = SimpleExpSmoothing(data)
fit_model = model.fit()

# 예측값 생성
predictions = fit_model.forecast(steps=10)  # 예측할 스텝 수

# 결과 출력
print(""예측값:"", predictions)
","예측값: [0.54753817 0.51288165 0.51288165 0.51288165 0.51288165 0.51288165 0.51288165 0.51288165 0.51288165 0.51288165]
",https://www.statsmodels.org/stable/generated/statsmodels.tsa.holtwinters.SimpleExpSmoothing.html#statsmodels.tsa.holtwinters.SimpleExpSmoothing
200,NumPy ,배열,슬라이싱,,,"arr[1:5:2]
","arr = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

# 슬라이싱: 인덱스 1부터 5 전까지 2 간격으로 요소 선택
result = arr[1:5:2]arr[1:5:2]","[1, 3]",https://docs.python.org/3/tutorial/introduction.html#lists
201,NumPy ,축,배열,연결,합치다,"np.concatenate((배열1, 배열2), axis=0)","import numpy as np

# 두 개의 샘플 배열 생성
array1 = np.array([[1, 2, 3],
                    [4, 5, 6]])

array2 = np.array([[7, 8, 9],
                    [10, 11, 12]])

# 축 0을 따라 연결 (행 방향)
result = np.concatenate((array1, array2), axis=0)

print(""Concatenated along axis 0:\n"", result)
","[[ 1 2 3] 
[ 4 5 6] 
[ 7 8 9] 
[10 11 12]]",https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html
202,NumPy ,np.where,조건,추출,배열,"np.where(조건, 참값_배열, 거짓값_배열)","# 샘플 배열 생성
array = np.array([[1, 2, 3],
                  [4, 5, 6],
                  [7, 8, 9]])

# 조건: 배열의 값이 5보다 크면 참으로, 아니면 거짓으로 설정
condition = (array > 5)

# 조건에 따라 참값 배열 또는 거짓값 배열 선택
result = np.where(condition, array, 0)

print(""Result based on condition:\n"", result)","[[0 0 0] 
[0 0 6] 
[7 8 9]]",https://numpy.org/doc/stable/reference/generated/numpy.where.html
203,NumPy,집계 함수,numpy.sum(), numpy.mean(),numpy.max(),"np.mean(배열)

","# 샘플 배열 생성
array = np.array([[1, 2, 3],
                  [4, 5, 6],
                  [7, 8, 9]])

# 배열의 전체 평균 계산
mean_value = np.mean(array)

print(""배열의 전체 평균:"", mean_value)
",5,https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html
204,NumPy ,연산,numpy.add(),numpy.subtract(),numpy.multiply(),"np.add(배열1, 배열2)","import numpy as np

# 샘플 배열 생성
array1 = np.array([[1, 2, 3],
                  [4, 5, 6]])

array2 = np.array([[7, 8, 9],
                  [10, 11, 12]])

# 두 배열의 요소별 합 계산
result = np.add(배열1, 배열2)

print(""array1과 array2의 요소별 합:\n"", result)
","[[ 8 10 12]
  [14 16 18]]",https://numpy.org/doc/stable/reference/generated/numpy.add.html
205,NumPy ,랜덤 배열,numpy.random.rand(),numpy.random.randn() ,,"np.random.randn(행의 수, 열의 수)","import numpy as np

# 3행 4열의 표준 정규 분포를 따르는 난수 생성
random_array = np.random.randn(3, 4)

print(""표준 정규 분포를 따르는 난수 배열:\n"", random_array)
","표준 정규 분포를 따르는 난수 배열:
 [[-0.43346413  0.12312451 -1.11077486  0.70437568]
 [ 1.37773244  0.65451757 -1.1468939  -0.02059376]
 [-0.34567058 -1.67281349 -0.98060137 -0.22148231]]
",https://numpy.org/doc/stable/reference/random/generated/numpy.random.randn.html
206,NumPy ,배열,형태,변경,numpy.reshape(),"np.reshape(배열, (새로운 행의 수, 새로운 열의 수))","import numpy as np

# 샘플 배열 생성
array = np.array([[1, 2, 3],
                  [4, 5, 6],
                  [7, 8, 9],
                  [10, 11, 12]])

# 배열을 2행 6열의 형태로 재구성
new_array = np.reshape(array, (2, 6))

print(""새로운 형태의 배열:\n"", new_array)
",새로운 형태의 배열: [[ 1 2 3 4 5 6] [ 7 8 9 10 11 12]],https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
207,NumPy ,배열,함수,적용,,"np.apply_along_axis(함수, axis, 배열)","import numpy as np

# 1차원 배열의 합을 계산하는 함수 정의
def sum_row(row):
    return np.sum(row)

# 2차원 배열 생성
arr = np.array([[1, 2, 3],
                [4, 5, 6]])

# axis 1(행)을 따라 sum_row 함수 적용
result = np.apply_along_axis(sum_row, axis=1, arr=arr)

# 결과 출력
print(result) 
",[ 6 15],https://numpy.org/doc/stable/reference/generated/numpy.apply_along_axis.html
208,배열,생성,numpy.array() ,,,"np.array([1, 2, 3])","import numpy as np

# 리스트를 이용한 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 결과 출력
print(arr) ",[1 2 3 4 5],https://numpy.org/doc/stable/reference/generated/numpy.array.html
209,배열,인덱스,엑세스,,,arr[0],"import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 첫 번째 요소 가져오기
first_element = arr[0]

# 결과 출력
print(""첫 번째 요소:"", first_element) 
",1,https://numpy.org/doc/stable/user/basics.indexing.html
210,특정 값,채우다,배열,numpy.full(),,"np.full((3, 3), 5)","import numpy as np

# 3x3 크기의 배열을 생성하고 값을 모두 5로 채움
arr = np.full((3, 3), 5)

# 결과 출력
print(arr)
","[[5 5 5]
 [5 5 5]
 [5 5 5]]
",https://numpy.org/doc/stable/reference/generated/numpy.full.html
211,numpy.arange() ,배열,범위,생성,,"np.arange(1, 10)","import numpy as np

# 1부터 10까지의 숫자로 이루어진 배열 생성
arr = np.arange(1, 10)

# 결과 출력
print(arr)
","[1 2 3 4 5 6 7 8 9]
",https://numpy.org/doc/stable/reference/generated/numpy.arange.html
212,Numpy,배열,복사,,,배열.copy(),"import numpy as np

# 원래 배열 생성
original_arr = np.array([1, 2, 3])

# 배열의 깊은 복사 생성
copied_arr = original_arr.copy()

# 원본 배열 변경
original_arr[0] = 100

# 결과 출력
print(""원본 배열:"", original_arr) 
print(""복사된 배열:"", copied_arr)
","원본 배열 :  [100   2   3]
복사된 배열 : [1 2 3]",https://numpy.org/doc/stable/reference/generated/numpy.ndarray.copy.html
213,NumPy ,배열,나누기,,,"np.split(arr, 2)","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5, 6])

# 배열을 두 개의 하위 배열로 분할
subarrays = np.split(arr, 2)

# 결과 출력
print(subarrays)
","[array([1, 2, 3]), array([4, 5, 6])]
",https://numpy.org/doc/stable/reference/generated/numpy.split.html
214,numpy.sum() ,배열,요소,더하기,,np.sum(배열),"import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열의 모든 요소의 합 계산
total_sum = np.sum(arr)

# 결과 출력
print(total_sum) ",15,https://numpy.org/doc/stable/reference/generated/numpy.sum.html
215,numpy.multiply(),배열,연산,,,"np.multiply(arr, 2)","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열의 각 요소에 2를 곱함
result = np.multiply(arr, 2)

# 결과 출력
print(result) 
",[ 2  4  6  8 10],https://numpy.org/doc/stable/reference/generated/numpy.multiply.html
216,numpy.astype(),타입 변환,,타입변환,,arr.astype(np.int32),"import numpy as np

# 배열 생성
arr = np.array([1.1, 2.2, 3.3, 4.4, 5.5])

# 배열의 데이터 타입을 np.int32로 변경
arr_int32 = arr.astype(np.int32)

# 결과 출력
print(arr_int32) 
",[1 2 3 4 5],https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html
217,NumPy ,배열,생성,numpy.array(),라이브러리,"numpy.array([1, 2, 3])","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3])

# 결과 출력
print(arr) 
",[1 2 3],https://numpy.org/doc/stable/reference/generated/numpy.array.html
218,NumPy ,연산자,베열,더하다,,"np.add(arr1, arr2)","import numpy as np

# 두 배열 생성
arr1 = np.array([1, 2, 3])
arr2 = np.array([4, 5, 6])

# 두 배열의 요소별 합 계산
result = np.add(arr1, arr2)

# 결과 출력
print(result) 
",[5 7 9],https://numpy.org/doc/stable/reference/generated/numpy.add.html
219,numpy.ndim,배열,차원,확인,NumPy,np.ndim(arr),"import numpy as np

# 배열 생성
arr = np.array([[1, 2, 3], [4, 5, 6]])

# 배열의 차원 수 확인
dimension = np.ndim(arr)

# 결과 출력
print(""배열의 차원 수:"", dimension)
",2,https://numpy.org/doc/stable/reference/generated/numpy.ndarray.ndim.html
220,슬라이싱,배열,요소,선택,,arr[시작:끝:스텝],"import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# 배열을 슬라이싱하여 요소 선택
selected_elements = arr[2:7:2]  # 인덱스 2부터 7까지(7은 포함하지 않음) 2간격으로 선택

# 결과 출력
print(selected_elements) 
",[3 5 7],https://numpy.org/doc/stable/user/basics.indexing.html
221,numpy.save() ,배열,파일,저장,,"np.save('파일명', 배열)","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열을 파일로 저장
np.save('my_array.npy', arr)
",,https://numpy.org/doc/stable/reference/generated/numpy.save.html
222,numpy.where() ,배열,특정 값,찾다,,np.where(arr == 값),"import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

# 배열에서 값이 5인 요소의 인덱스 찾기
indices = np.where(arr == 5)

# 결과 출력
print(indices)
","(array([4]),)",https://numpy.org/doc/stable/reference/generated/numpy.where.html
223,numpy.max(),배열,최댓값,,,np.max(arr),"import numpy as np

# 배열 생성
arr = np.array([1, 5, 3, 9, 7])

# 배열에서 최대값 찾기
max_value = np.max(arr)

# 결과 출력
print(max_value) 
",9,https://numpy.org/doc/stable/reference/generated/numpy.max.html
224,데이터프레임,유일한 값,추출,,,"df[""열 이름""].unique()","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 2, 3, 4],
        'B': ['a', 'b', 'c', 'c', 'd']}
df = pd.DataFrame(data)

# ""A"" 열의 고유한 값들 반환
unique_values = df[""A""].unique()

# 결과 출력
print(unique_values)
",[1 2 3 4],https://pandas.pydata.org/docs/reference/api/pandas.Series.unique.html
225,NumPy ,배열,연결,결합,,"np.concatenate((arr1, arr2))","import numpy as np

# 두 개의 배열 생성
arr1 = np.array([1, 2, 3])
arr2 = np.array([4, 5, 6])

# 두 배열 연결
concatenated_arr = np.concatenate((arr1, arr2))

# 결과 출력
print(concatenated_arr) 
",[1 2 3 4 5 6],https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html
226,리스트,NumPy,배열,변경,array(),np.array(리스트),"import numpy as np

# 리스트 생성
my_list = [1, 2, 3, 4, 5]

# 배열로 변환
my_array = np.array(my_list)

# 결과 출력
print(my_array)
",[1 2 3 4 5],https://numpy.org/doc/stable/reference/generated/numpy.array.html
227,DataFrame,데이터프레임,추가,assign(),열,df.assign(new_column=값),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 새로운 열 추가
df = df.assign(new_column=[10, 20, 30])

# 결과 출력
print(df)
","   A  B  new_column
0  1  a          10
1  2  b          20
2  3  c          30
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.assign.html
228,DataFrame,선택,loc,행,편집,"df.loc[인덱스, ""컬럼명""] = 값","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 값 할당
df.loc[1, ""A""] = 10

# 결과 출력
print(df)
","    A  B
0   1  a
1  10  b
2   3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html
229,DataFrame,행,삭제,drop(),열,df.drop(인덱스),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 특정 인덱스 삭제
df = df.drop(1)

# 결과 출력
print(df)
","   A  B
0  1  a
2  3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html
230,DataFrame,필터링,query() ,filter() ,,"df.query(""조건식"")","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 조건식을 사용하여 특정 조건을 만족하는 행 선택
filtered_df = df.query(""A > 1"")

# 결과 출력
print(filtered_df)
","   A  B
1  2  b
2  3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html
231,DataFrame,그래프,시각화,plot,matplotlib,"df.plot(kind=""bar"")","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3, 4, 5],
        'B': [5, 4, 3, 2, 1]}
df = pd.DataFrame(data)

# 막대 그래프로 시각화
df.plot(kind=""bar"")
",,https://pandas.pydata.org/docs/getting_started/intro_tutorials/09_timeseries.html
232,DataFrame,형식,변환,to_csv(),to_excel(),"df.to_csv(""파일명.csv"")","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# DataFrame을 CSV 파일로 저장
df.to_csv(""my_data.csv"", index=False)
",,https://pandas.pydata.org/docs/getting_started/intro_tutorials/02_read_write.html
233,DataFrame,통계적,분석,describe(),mean(),df.describe(),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3, 4, 5],
        'B': [5, 4, 3, 2, 1]}
df = pd.DataFrame(data)

# DataFrame의 기술 통계량 출력
print(df.describe())
","              A         B
count  5.000000  5.000000
mean   3.000000  3.000000
std    1.581139  1.581139
min    1.000000  1.000000
25%    2.000000  2.000000
50%    3.000000  3.000000
75%    4.000000  4.000000
max    5.000000  5.000000
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html
234,DataFrame,그룹화,집계,판다스,,groupby(),"import pandas as pd

# DataFrame 생성
data = {'Team': ['A', 'B', 'A', 'B', 'A'],
        'Points': [10, 20, 15, 25, 30]}
df = pd.DataFrame(data)

# 'Team' 열을 기준으로 그룹화하여 각 그룹의 합을 계산
grouped = df.groupby('Team').sum()

# 결과 출력
print(grouped)
","      Points
Team        
A         55
B         45
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/06_calculate_statistics.html
235,DataFrame,행,추가,append() ,,df.append(새로운행),"import pandas as pd

# 기존 DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 새로운 행 생성
new_row = {'A': 4, 'B': 'd'}

# DataFrame에 새로운 행 추가
df = df.append(new_row, ignore_index=True)

# 결과 출력
print(df)
","   A  B
0  1  a
1  2  b
2  3  c
3  4  d
",https://pandas.pydata.org/pandas-docs/version/1.3/reference/api/pandas.DataFrame.append.html
236,pandas,데이터프레임,행,추가,DataFrame.loc[] ,df.loc[새로운인덱스] = 새로운행,"import pandas as pd

# 기존 DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 새로운 행 추가
df.loc[3] = [4, 'd']

# 결과 출력
print(df)
","   A  B
0  1  a
1  2  b
2  3  c
3  4  d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html
237,pandas,특정 열,필터링,DataFrame.query(),,df.query('열이름 == 값'),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 열 'A'의 값이 2인 행 필터링
filtered_df = df.query('A == 2')

# 결과 출력
print(filtered_df)
","   A  B
1  2  b
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html
238,pandas,값,계산,DataFrame.apply(),,"df.apply(함수, 축=인덱스)","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': [4, 5, 6]}
df = pd.DataFrame(data)

# 함수 정의
def my_function(x):
    return x * 2

# 열 방향으로 함수 적용
result = df.apply(my_function, axis=0)

# 결과 출력
print(result)
","   A   B
0  2   8
1  4  10
2  6  12
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html
239,pandas,범주형,추가,Series.astype() ,,df['새로운속성'].astype('범주'),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 'B' 열을 범주형으로 변환
df['B'] = df['B'].astype('category')

# 결과 출력
print(df.dtypes)
","A       int64
B    category
dtype: object
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html
240,pandas,중복값,확인,DataFrame.duplicated() ,,df.duplicated(),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 2, 3, 4],
        'B': ['a', 'b', 'b', 'c', 'd']}
df = pd.DataFrame(data)

# 중복된 행 확인
duplicated_rows = df.duplicated()

# 결과 출력
print(duplicated_rows)
","0    False
1    False
2     True
3    False
4    False
dtype: bool
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html
241,pandas,행,샘플링,DataFrame.sample() ,,df.sample(n=샘플크기),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3, 4, 5],
        'B': ['a', 'b', 'c', 'd', 'e']}
df = pd.DataFrame(data)

# DataFrame에서 3개의 랜덤 샘플링
sampled_df = df.sample(n=3)

# 결과 출력
print(sampled_df)
","   A  B
0  1  a
3  4  d
2  3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html
242,데이터프레임,만들다,pandas.DataFrame() ,생성,,df = pd.DataFrame(데이터),"import pandas as pd

# 데이터 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}

# 데이터프레임 생성
df = pd.DataFrame(data)

# 결과 출력
print(df)
","   A  B
0  1  a
1  2  b
2  3  c
",https://pandas.pydata.org/docs/getting_started/intro_tutorials/01_table_oriented.html
243,데이터프레임,행,추가,append(),판다스,"df = df.append(새로운_행, ignore_index=True)","import pandas as pd

# 기존 데이터프레임 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 새로운 행 생성
new_row = {'A': 4, 'B': 'd'}

# 데이터프레임에 새로운 행 추가
df = df.append(new_row, ignore_index=True)

# 결과 출력
print(df)
","   A  B
0  1  a
1  2  b
2  3  c
3  4  d
",https://pandas.pydata.org/pandas-docs/version/1.3/reference/api/pandas.DataFrame.append.html
244,열,선택,DataFrame.loc[] ,DataFrame.iloc[],,df[['열_이름']],"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# loc를 사용하여 특정 행 선택
selected_row = df.loc[1, ['A']]

# 결과 출력
print(selected_row)
","A    2
Name: 1, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html
245,데이터프레임,열,추가,,,df['새로운_열'] = 새로운_열_데이터,"import pandas as pd

# 기존 데이터프레임 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 새로운 열 데이터 생성
new_column_data = [4, 5, 6]

# 데이터프레임에 새로운 열 추가
df['새로운_열'] = new_column_data

# 결과 출력
print(df)
","   A  B  새로운_열
0  1  a       4
1  2  b       5
2  3  c       6
",https://numpy.org/doc/stable/user/basics.indexing.html
246,데이터,처리,빠지다,NaN ,,df.fillna(0) # 0으로 채움,"import pandas as pd
import numpy as np

# NaN 값을 포함한 DataFrame 생성
data = {'A': [1, np.nan, 3],
        'B': [np.nan, 5, np.nan]}
df = pd.DataFrame(data)

# NaN 값을 0으로 채움
filled_df = df.fillna(0)

# 결과 출력
print(filled_df)
","     A    B
0  1.0  0.0
1  0.0  5.0
2  3.0  0.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html
247,데이터프레임,정렬,행,열,sort,df.sort_values(열_이름),"import pandas as pd

# DataFrame 생성
data = {'A': [3, 1, 2],
        'B': ['c', 'a', 'b']}
df = pd.DataFrame(data)

# 'A' 열을 기준으로 정렬
sorted_df = df.sort_values('A')

# 결과 출력
print(sorted_df)
","   A  B
1  1  a
2  2  b
0  3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html
248,데이터프레임,필터링,조건,,,"df.query(""조건"")","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3, 4, 5],
        'B': ['a', 'b', 'c', 'd', 'e']}
df = pd.DataFrame(data)

# 'A' 열 값이 3보다 큰 행 필터링
filtered_df = df.query(""A > 3"")

# 결과 출력
print(filtered_df)
","   A  B
3  4  d
4  5  e
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.query.html
249,데이터프레임,행,함수,적용,apply(),"df.apply(함수, 축=1)","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': [4, 5, 6]}
df = pd.DataFrame(data)

# 함수 정의
def sum_row(row):
    return row['A'] + row['B']

# 각 행에 함수 적용
result = df.apply(sum_row, axis=1)

# 결과 출력
print(result)
","0    5
1    7
2    9
dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html
250,데이터터프레임,csv,저장,,,df.to_csv('파일_경로.csv'),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# DataFrame을 CSV 파일로 저장
df.to_csv('my_data.csv', index=False)
",,https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html
251,pandas,데이터프레임,loc,append(),추가,df.loc[df.index.max() + 1] = ['새로운 데이터'],"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df = pd.DataFrame(data)

# 새로운 데이터를 포함한 리스트 생성
new_row_data = ['새로운 데이터']

# DataFrame에 새로운 행 추가
df.loc[df.index.max() + 1] = new_row_data

# 결과 출력
print(df)
","     A  B
0    1  a
1    2  b
2    3  c
3  NaN  새로운 데이터
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html
252,pandas,열,인덱서,선택,,df['열 이름'],"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': [4, 5, 6]}
df = pd.DataFrame(data)

# 열에서 인덱서 선택
selected_column = df['A']

# 결과 출력
print(selected_column)
","0    1
1    2
2    3
Name: A, dtype: int64
",https://numpy.org/doc/stable/user/absolute_beginners.html
253,pandas,drop_duplicates(),중복,제거,판다스,df.drop_duplicates(),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 2, 3, 4],
        'B': ['a', 'b', 'b', 'c', 'd']}
df = pd.DataFrame(data)

# 중복된 행 제거
deduplicated_df = df.drop_duplicates()

# 결과 출력
print(deduplicated_df)
","   A  B
0  1  a
1  2  b
3  3  c
4  4  d
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html
254,pandas,특정 값,교체,replace() ,,"df['열 이름'].replace(기존 값, 새로운 값)","import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3, 4, 5],
        'B': ['a', 'b', 'c', 'a', 'b']}
df = pd.DataFrame(data)

# 'B' 열에서 'a'를 'x'로 교체
df['B'] = df['B'].replace('a', 'x')

# 결과 출력
print(df)
","   A  B
0  1  x
1  2  b
2  3  c
3  4  x
4  5  b
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html
255,판다스,데이터프레임,결합,,,"pd.concat([df1, df2], axis=1)","import pandas as pd

# 첫 번째 DataFrame 생성
data1 = {'A': [1, 2, 3],
         'B': ['a', 'b', 'c']}
df1 = pd.DataFrame(data1)

# 두 번째 DataFrame 생성
data2 = {'C': [4, 5, 6],
         'D': ['x', 'y', 'z']}
df2 = pd.DataFrame(data2)

# 두 DataFrame을 열 방향으로 병합
result = pd.concat([df1, df2], axis=1)

# 결과 출력
print(result)
","   A  B  C  D
0  1  a  4  x
1  2  b  5  y
2  3  c  6  z
",https://pandas.pydata.org/docs/reference/api/pandas.concat.html
256,판다스,열,이름,변경,,df1.rename(columns={'old_name': 'new_name'}),"import pandas as pd

# DataFrame 생성
data = {'old_name': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df1 = pd.DataFrame(data)

# 열 이름 변경
df1 = df1.rename(columns={'old_name': 'new_name'})

# 결과 출력
print(df1)
","   new_name  B
0         1  a
1         2  b
2         3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html
257,판다스,데이터프레임,인덱스,설정,,df1.set_index(['index_column']),"import pandas as pd

# DataFrame 생성
data = {'A': [1, 2, 3],
        'B': ['a', 'b', 'c']}
df1 = pd.DataFrame(data)

# 인덱스 변경
df1 = df1.set_index(['A'])

# 결과 출력
print(df1)
","   B
A   
1  a
2  b
3  c
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.set_index.html
258,행렬,생성,matrix,연산,,"np.matrix([[1, 2], [3, 4]])","import numpy as np

# 행렬 생성
matrix = np.matrix([[1, 2], [3, 4]])

# 결과 출력
print(matrix)
","[[1 2]
 [3 4]]
",https://numpy.org/doc/stable/reference/generated/numpy.matrix.html
259,배열,추가,빼기,연산자,,배열1 + 배열2,"import numpy as np

# 배열 생성
a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

# 배열 더하기
c = a + b","[5, 7, 9]",https://numpy.org/doc/stable/user/quickstart.html#basic-operations
260,배열,곱하기,연산자,numpy.dot(),,"a * b (요소별 곱셉), np.dot(a, b) (행렬 곱셉)","import numpy as np

# 배열 생성
a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

# 요소별 곱셈
elementwise_product = a * b

# 행렬 곱셈
dot_product = np.dot(a, b)

# 결과 출력
print(""요소별 곱셈 결과:"", elementwise_product)
print(""행렬 곱셈 결과:"", dot_product)
","요소별 곱셈 결과: [ 4 10 18]
행렬 곱셈 결과: 32
",https://numpy.org/doc/stable/reference/generated/numpy.dot.html
261,배열,모양,확인,크기,shape,a.shape,"import numpy as np

# 배열 생성
a = np.array([[1, 2, 3], [4, 5, 6]])

# 배열의 모양 확인
shape = a.shape

# 결과 출력
print(""배열의 모양:"", shape)
","배열의 모양: (2, 3)",https://numpy.org/doc/stable/reference/generated/numpy.shape.html
262,배열,통계,추출,,,"numpy.mean(), numpy.median(), numpy.std()","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열의 평균 계산
mean_value = np.mean(arr)

# 배열의 중앙값 계산
median_value = np.median(arr)

# 배열의 표준편차 계산
std_value = np.std(arr)

# 결과 출력
print(""배열의 평균:"", mean_value)
print(""배열의 중앙값:"", median_value)
print(""배열의 표준편차:"", std_value)
","배열의 평균: 3.0
배열의 중앙값: 3.0
배열의 표준편차: 1.4142135623730951",https://numpy.org/doc/stable/reference/generated/numpy.mean.html
263,배열,파일,저장,,,"np.save('배열.npy', a)","import numpy as np

# 배열 생성
a = np.array([[1, 2, 3], [4, 5, 6]])

# 배열을 파일로 저장
np.save('배열.npy', a)
",,https://numpy.org/doc/stable/reference/generated/numpy.fromfile.html
264,파일,배열,불러오기,로드,,a = np.load('배열.npy'),"import numpy as np

# 배열 파일 불러오기
a = np.load('배열.npy')
",,https://numpy.org/doc/stable/reference/generated/numpy.fromfile.html
265,NumPy ,배열,값,곱하기,,np.prod(배열),"import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열의 모든 요소의 곱 계산
result = np.prod(arr)

# 결과 출력
print(""배열의 모든 요소의 곱:"", result)
",배열의 모든 요소의 곱: 120,https://numpy.org/doc/stable/reference/generated/numpy.prod.html
266,NumPy ,배열,반복,for,,for 값 in 배열,"import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열의 각 요소에 대해 반복
for value in arr:
    print(value)
","1
2
3
4
5",https://numpy.org/doc/stable/reference/arrays.nditer.html
267,NumPy,배열,정렬,요소,,np.sort(배열),"import numpy as np

# 배열 생성
arr = np.array([3, 1, 2, 5, 4])

# 배열 정렬
sorted_arr = np.sort(arr)

# 결과 출력
print(""정렬된 배열:"", sorted_arr)
","정렬된 배열: [1 2 3 4 5]
",https://numpy.org/doc/stable/reference/generated/numpy.sort.html
268,NumPy ,배열,요소별 연산,연산자,오버로딩,배열1 + 배열2,"import numpy as np

# 배열 생성
arr1 = np.array([1, 2, 3])
arr2 = np.array([4, 5, 6])

# 배열 더하기
result = arr1 + arr2

# 결과 출력
print(""배열1 + 배열2:"", result)
","배열1 + 배열2: [5 7 9]
",https://numpy.org/doc/stable/user/basics.indexing.html
269,2차원,배열,행렬,생성,,"np.array([[1, 2], [3, 4]])","import numpy as np

# 배열 생성
arr = np.array([[1, 2], [3, 4]])

# 결과 출력
print(arr)
","[[1 2]
 [3 4]]
",https://numpy.org/doc/stable/user/basics.indexing.html
270,배열,요소,역순,할당,,np.flip(배열),"import numpy as np

# 배열 생성
arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

# 배열 뒤집기
flipped_arr = np.flip(arr)

# 결과 출력
print(""\n뒤집힌 배열:"")
print(flipped_arr)
","
뒤집힌 배열:
[[9 8 7]
 [6 5 4]
 [3 2 1]]
",https://numpy.org/doc/stable/reference/generated/numpy.flip.html
271,배열,특정 요소,인덱싱,접근,,배열[행인덱스][열인덱스],"import numpy as np

# 배열 생성
arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

# 특정 요소에 접근
element = arr[1][2]

# 결과 출력
print(""특정 요소:"", element)
",특정 요소: 6,https://numpy.org/doc/stable/user/basics.indexing.html
272,배열,값,삽입,,,"np.insert(배열, 인덱스, 값)","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열에 요소 삽입
new_arr = np.insert(arr, 2, 10)

# 결과 출력
print(""배열:"", arr)
print(""요소가 삽입된 배열:"", new_arr)
","배열: [1 2 3 4 5]
요소가 삽입된 배열: [ 1  2 10  3  4  5]
",https://numpy.org/doc/stable/reference/generated/numpy.insert.html
273,배열,모든 요소,특정 값,할당,,"np.full(배열, 값)","import numpy as np

# 배열 생성
arr = np.array([[1, 2, 3], [4, 5, 6]])

# 배열을 값으로 채우기
np.full(arr.shape, 10, out=arr)

# 결과 출력
print(""배열:"", arr)
","배열: [[10 10 10]
 [10 10 10]]
",https://numpy.org/doc/stable/reference/generated/numpy.ndarray.fill.html
274,numpy.array(),dtype,배열,생성,,"np.array(리스트, dtype=numpy.int)","import numpy as np

# 리스트 생성
my_list = [1.5, 2.7, 3.8]

# 배열 생성
arr = np.array(my_list, dtype=np.int)

# 결과 출력
print(""배열:"", arr)
","배열: [1 2 3]
",https://numpy.org/doc/stable/reference/generated/numpy.array.html
275,NumPy,배열,균일 분포,생성,numpy.random.rand(),"np.random.rand(행, 열)","import numpy as np

# 난수 배열 생성
rand_array = np.random.rand(2, 3)

# 결과 출력
print(""난수 배열:"")
print(rand_array)
","난수 배열:
[[0.60294581 0.43258616 0.61835857]
 [0.51307135 0.51663288 0.77576293]]
",https://numpy.org/doc/stable/reference/random/generated/numpy.random.rand.html
276,NumPy,배열,크기,변경,,"np.resize(배열, (새 행, 새 열))","import numpy as np

# 배열 생성
arr = np.array([[1, 2], [3, 4]])

# 배열 크기 변경
resized_arr = np.resize(arr, (3, 3))

# 결과 출력
print(""크기 변경된 배열:"")
print(resized_arr)
","크기 변경된 배열:
[[1 2 3]
 [4 1 2]
 [3 4 1]]
",https://numpy.org/doc/stable/reference/generated/numpy.resize.html
277,행,열,삭제,추가,,"np.insert(배열, 인덱스, 값), np.delete(배열, 인덱스)","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열에 요소 삽입
new_arr = np.insert(arr, 2, 10)

# 배열에서 요소 삭제
new_arr = np.delete(new_arr, 3)

# 결과 출력
print(""요소가 삽입된 배열:"", new_arr)
","요소가 삽입된 배열: [ 1  2 10  4  5]
",https://numpy.org/doc/stable/reference/generated/numpy.insert.html
278,NumPy,배열,수정,인덱싱,numpy.put(),"배열[인덱스] = 값, np.put(배열, 인덱스, 값)","import numpy as np

# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 배열의 특정 인덱스에 직접 값을 할당
arr[2] = 10

# 결과 출력
print(""직접 값 할당 결과:"", arr)

# np.put() 함수를 사용하여 배열의 특정 인덱스에 값 삽입
np.put(arr, [3], [20])

# 결과 출력
print(""np.put() 함수 사용 결과:"", arr)
","직접 값 할당 결과: [ 1  2 10  4  5]
np.put() 함수 사용 결과: [ 1  2 10 20  5]
",https://numpy.org/doc/stable/reference/generated/numpy.put.html
279,NumPy,배열,뷰,생성,,view,"
# 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# view 생성
arr_view = arr.view()",[ 1  2 10  4  5],https://numpy.org/doc/stable/reference/generated/numpy.ndarray.view.html
280,NumPy,배열,새로운 차원,추가,,np.newaxis(배열),"import numpy as np

# 1차원 배열 생성
arr = np.array([1, 2, 3, 4, 5])

# 새로운 축 추가
new_arr = arr[:, np.newaxis]

# 결과 출력
print(""새로운 축이 추가된 배열:"")
print(new_arr)
","새로운 축이 추가된 배열:
[[1]
 [2]
 [3]
 [4]
 [5]]
",https://numpy.org/doc/stable/reference/constants.html
281,NumPy,요소,True,배열,인덱스,np.argwhere(배열),"import numpy as np

# 배열 생성
arr = np.array([[0, 1, 0],
                [1, 0, 1]])

# 배열에서 값이 True인 요소의 인덱스 찾기
indices = np.argwhere(arr)

# 결과 출력
print(""배열에서 값이 True인 요소의 인덱스:"")
print(indices)
","배열에서 값이 True인 요소의 인덱스:
[[0 1]
 [1 0]
 [1 2]]
",https://numpy.org/doc/stable/reference/generated/numpy.argwhere.html
282,파이썬,NumPy,pip,명령어,설치,pip install numpy,!pip install numpy,,https://numpy.org/install/
283,NumPy,배열,연산자,사칙 연산자,,arr1 + arr2,"import numpy as np

# 배열 생성
arr1 = np.array([1, 2, 3])
arr2 = np.array([4, 5, 6])

# 배열끼리의 요소별 덧셈
result = arr1 + arr2

# 결과 출력
print(""요소별 덧셈 결과:"", result)
","요소별 덧셈 결과: [5 7 9]
",https://numpy.org/doc/stable/user/quickstart.html#basic-operations
284,특정 값,개수,세기,value_counts(),,"df[""열 이름""].value_counts()","import pandas as pd

# 데이터프레임 생성
data = {'A': [1, 2, 2, 3, 3, 3],
        'B': ['a', 'b', 'b', 'c', 'c', 'c']}
df = pd.DataFrame(data)

# 열의 고유 값의 빈도 계산
value_counts = df[""A""].value_counts()

# 결과 출력
print(""열 A의 고유 값의 빈도:"")
print(value_counts)
","열 A의 고유 값의 빈도:
3    3
2    2
1    1
Name: A, dtype: int64
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.value_counts.html
285,파이썬,데이터프레임,데이터,표 형식,데이터 구조,DataFrame(데이터),"import pandas as pd

# 데이터 생성
data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],
        'Age': [28, 35, 40, 25],
        'City': ['New York', 'Paris', 'London', 'Berlin']}

# DataFrame 생성
df = pd.DataFrame(data)

# DataFrame 출력
print(""DataFrame:"")
print(df)
","DataFrame:
    Name  Age      City
0   John   28  New York
1   Anna   35     Paris
2  Peter   40    London
3  Linda   25    Berlin
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html
286,데이터프레임,로드,읽기 함수,,,pd.read_csv('파일명.csv'),"import pandas as pd

# CSV 파일 읽어들이기
df = pd.read_csv('파일명.csv')

# 결과 출력
print(""CSV 파일을 읽어들인 DataFrame:"")
print(df)
",,https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html
287,isnull() 함수,결측값,찾기,,,df[df.컬럼.isnull()],"import pandas as pd

# 데이터 생성
data = {'Name': ['John', 'Anna', None, 'Linda'],
        'Age': [28, None, 40, 25],
        'City': ['New York', 'Paris', 'London', None]}

# DataFrame 생성
df = pd.DataFrame(data)

# 특정 컬럼이 null인 행 필터링
result = df[df['Name'].isnull()]

# 결과 출력
print(""특정 컬럼이 null인 행:"")
print(result)
","특정 컬럼이 null인 행:
   Name   Age    City
2  None  40.0  London
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html
288,데이터프레임,상위,행,head(),,df.head(n),"import pandas as pd

# 데이터 생성
data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],
        'Age': [28, 35, 40, 25],
        'City': ['New York', 'Paris', 'London', 'Berlin']}

# DataFrame 생성
df = pd.DataFrame(data)

# 처음 2개의 행 반환
result = df.head(2)

# 결과 출력
print(""처음 2개의 행:"")
print(result)
","처음 2개의 행:
   Name  Age      City
0  John   28  New York
1  Anna   35     Paris
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html
289,데이터프레임,최하위,행,tail(),,df.tail(n),"import pandas as pd

# 데이터 생성
data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],
        'Age': [28, 35, 40, 25],
        'City': ['New York', 'Paris', 'London', 'Berlin']}

# DataFrame 생성
df = pd.DataFrame(data)

# 마지막 2개의 행 반환
result = df.tail(2)

# 결과 출력
print(""마지막 2개의 행:"")
print(result)
","마지막 2개의 행:
    Name  Age    City
2  Peter   40  London
3  Linda   25  Berlin
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.tail.html
290,데이터프레임,조건,만족,행,count(),"
count_A = df['A'].count() 
","# 예시 데이터프레임 생성 
data = { 'A': [1, 2, 3, None, 5], 'B': ['a', 'b', 'c', 'd', None] } 
df = pd.DataFrame(data)

# 'A' 컬럼에서 결측값이 아닌 값의 개수 세기 
count_A = df['A'].count() 
print(count_A)",4,https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.count.html
291,데이터프레임,특정 컬럼,대괄호,컬럼 이름,접근,df['컬럼명'],"import pandas as pd

# 예시 데이터프레임 생성
data = {'A': [1, 2, 3, None, 5],
        'B': ['a', 'b', 'c', 'd', None]}
df = pd.DataFrame(data)

# 'A' 컬럼에 접근하여 데이터 출력
print(df['A'])
","0    1.0
1    2.0
2    3.0
3    NaN
4    5.0
Name: A, dtype: float64
",https://numpy.org/doc/stable/user/basics.indexing.html
292,DataFrame,결측값,처리,,,df.dropna(how='any'),"import pandas as pd

# 예시 데이터프레임 생성
data = {'A': [1, 2, 3, None, 5],
        'B': ['a', 'b', 'c', 'd', None]}
df = pd.DataFrame(data)

# 결측값이 있는 모든 행 제거
df_dropped = df.dropna(how='any')

# 결과 출력
print(""결측값이 있는 모든 행 제거 결과:"")
print(df_dropped)
","결측값이 있는 모든 행 제거 결과:
     A  B
0  1.0  a
1  2.0  b
2  3.0  c
4  5.0  None
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html
293,DataFrame,시각화,라이브러리,,,df.plot(),"import pandas as pd
import matplotlib.pyplot as plt

# 예시 데이터프레임 생성
data = {'A': [1, 2, 3, 4, 5],
        'B': [5, 4, 3, 2, 1]}
df = pd.DataFrame(data)

# 데이터프레임 시각화
df.plot()

",,https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html
294,DataFrame,병합,,,,"pd.merge(df1, df2, on=""일치하는 열"")","# 예시 데이터프레임 생성
data1 = {'key': ['A', 'B', 'C', 'D'],
         'value': [1, 2, 3, 4]}
df1 = pd.DataFrame(data1)

data2 = {'key': ['B', 'D', 'E', 'F'],
         'value': [5, 6, 7, 8]}
df2 = pd.DataFrame(data2)

# 두 데이터프레임 병합
merged_df = pd.merge(df1, df2, on=""key"")

# 결과 출력
print(""두 데이터프레임을 병합한 결과:"")
print(merged_df)
","두 데이터프레임을 병합한 결과:
  key  value_x  value_y
0   B        2        5
1   D        4        6
",https://pandas.pydata.org/docs/reference/api/pandas.merge.html
295,DataFrame,그룹화,집계,집계 함수,,"df.groupby(""열"").mean()","import pandas as pd

# 예시 데이터프레임 생성
data = {'Group': ['A', 'B', 'A', 'B', 'A'],
        'Value': [1, 2, 3, 4, 5]}
df = pd.DataFrame(data)

# 열을 기준으로 그룹화하고 평균 계산
result = df.groupby(""Group"").mean()

# 결과 출력
print(""열을 기준으로 그룹화하여 평균 계산한 결과:"")
print(result)
","열을 기준으로 그룹화하여 평균 계산한 결과:
       Value
Group       
A         3.0
B         3.0
",https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html
296,다양한 차원,배열,1차원,만들기,2차원,"np.array([[1, 2, 3], [4, 5, 6]]) # 2차원 배열","import numpy as np

# 2차원 배열 생성
arr_2d = np.array([[1, 2, 3], [4, 5, 6]])

# 결과 출력
print(""2차원 배열:"")
print(arr_2d)
","2차원 배열:
[[1 2 3]
 [4 5 6]]
",https://numpy.org/doc/stable/reference/generated/numpy.array.html
297,배열,초기화,numpy.zeros(),0,,np.zeros(배열 크기),"import numpy as np

# 3x3 크기의 0으로 채워진 배열 생성
arr_zeros = np.zeros((3, 3))

# 결과 출력
print(""3x3 크기의 0으로 채워진 배열:"")
print(arr_zeros)
","3x3 크기의 0으로 채워진 배열:
[[0. 0. 0.]
 [0. 0. 0.]
 [0. 0. 0.]]
",https://numpy.org/doc/stable/reference/generated/numpy.zeros.html
298,리스트,NumPy,바꾸다,배열,np.array(리스트),"a = [1, 2, 3]; np.array(a)","import numpy as np

# 리스트 생성
a = [1, 2, 3]

# 리스트를 NumPy 배열로 변환
arr = np.array(a)

# 결과 출력
print(""리스트를 NumPy 배열로 변환한 결과:"")
print(arr)
print(""배열의 타입:"", type(arr))
","리스트를 NumPy 배열로 변환한 결과:
[1 2 3]
배열의 타입: <class 'numpy.ndarray'>
",https://numpy.org/doc/stable/reference/generated/numpy.array.html
299,NumPy,행렬,변환,np.matrix,,"a = np.array([[1, 2], [3, 4]])","np.matrix([[1, 2], [3, 4]])","matrix([[1, 2],
        [3, 4]])",https://numpy.org/doc/stable/reference/generated/numpy.matrix.html
300,배열,복사,numpy.copy(),,,b = a.copy(),"x = np.array([[1,2,3],[4,5,6]], order='F')
y = x.copy()
y","array([[1, 2, 3],
       [4, 5, 6]])",https://numpy.org/doc/stable/reference/generated/numpy.ndarray.copy.html
301,NumPy,배열,다차원 배열,,,"np.array(리스트).reshape(행, 열)","a = np.arange(6).reshape((3, 2))
a","array([[0, 1],
       [2, 3],
       [4, 5]])",https://numpy.org/doc/stable/reference/generated/numpy.reshape.html
302,배열의 크기,numpy.shape,,,,np.array(리스트).shape,"arr3 = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])
print(arr3.shape)

","(2, 2, 3)
",https://numpy.org/doc/stable/reference/generated/numpy.shape.html
303,배열,균등,분할,numpy.array_split(),,"분할된_배열 = numpy.array_split(배열, 균등한_부분)","x = np.arange(9)
np.array_split(x, 4)","[array([0, 1, 2]), array([3, 4]), array([5, 6]), array([7, 8])]",https://numpy.org/doc/stable/reference/generated/numpy.array_split.html
304,배열,최댓값,np.max(),,,최대값 = np.max(배열),"a = np.arange(4).reshape((2,2))
np.max(a) ",3,https://numpy.org/doc/stable/reference/generated/numpy.max.html
305,배열,요소,삭제,numpy.delete() ,,"np.delete(np.array([1, 2, 3]), 1)","arr = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])
np.delete(arr, 1, 0)","array([[ 1,  2,  3,  4],
       [ 9, 10, 11, 12]])",https://numpy.org/doc/stable/reference/generated/numpy.delete.html
306,hstack(),행렬,추가,열,행,"np.hstack((arr1, arr2)) # arr1과 arr2를 가로로 결합","a = np.array([[1],[2],[3]])
b = np.array([[4],[5],[6]])
np.hstack((a,b))","array([[1, 4],
       [2, 5],
       [3, 6]])",https://numpy.org/doc/stable/reference/generated/numpy.hstack.html
