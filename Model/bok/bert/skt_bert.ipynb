{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KoBert 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bok/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForSequenceClassification, BertModel\n",
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 안녕하세요 반갑습니다\n",
      "예측된 감정: negative\n",
      "확률: [[0.5940529108047485, 0.40594708919525146]]\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토큰 불러오기\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1')\n",
    "\n",
    "# 입력 문장 정의\n",
    "input_text = '안녕하세요 반갑습니다'\n",
    "\n",
    "# 입력 문장 토큰화\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 모델 예측\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# 출력 로짓(logits)을 소프트맥스 확률로 변환\n",
    "probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "\n",
    "# 가장 높은 확률을 가지는 클래스 선택\n",
    "predicted_class = torch.argmax(probabilities, dim=-1).item()\n",
    "\n",
    "# 감정 레이블 정의 (모델에 따라 다를 수 있음)\n",
    "labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# 예측된 감정 출력\n",
    "print(f\"문장: {input_text}\")\n",
    "print(f\"예측된 감정: {labels[predicted_class]}\")\n",
    "print(f\"확률: {probabilities.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>데이터프레임에서 특정 값을 기준으로 데이터를 필터링하려면 어떻게 해야 하나요?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>데이터프레임의 인덱스를 변경하려면 어떻게 해야 하나요?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>데이터프레임의 컬럼 이름을 변경하려면 어떻게 해야 하나요?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>데이터 프레임에 새로운 행을 추가하려면 어떻게 해야 하나요?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>데이터프레임의 행을 삭제하려면 어떻게 해야 하나요?</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      question label\n",
       "0  데이터프레임에서 특정 값을 기준으로 데이터를 필터링하려면 어떻게 해야 하나요?   yes\n",
       "1               데이터프레임의 인덱스를 변경하려면 어떻게 해야 하나요?   yes\n",
       "2             데이터프레임의 컬럼 이름을 변경하려면 어떻게 해야 하나요?   yes\n",
       "3            데이터 프레임에 새로운 행을 추가하려면 어떻게 해야 하나요?   yes\n",
       "4                 데이터프레임의 행을 삭제하려면 어떻게 해야 하나요?   yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('./model/data/train_set.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 정의\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90033/1444296744.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.label = df.label.replace({'yes': 1, 'no': 0})\n"
     ]
    }
   ],
   "source": [
    "# 데이터 준비\n",
    "texts = df.question.tolist()\n",
    "df.label = df.label.replace({'yes': 1, 'no': 0})\n",
    "labels = df.label.tolist()\n",
    "\n",
    "max_len = 128\n",
    "batch_size = 2\n",
    "\n",
    "dataset = SentimentDataset(texts, labels, tokenizer, max_len)\n",
    "data_loader = DataLoader(dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 가중치 초기화 함수\n",
    "def initialize_weights(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        module.weight.data.normal_(mean=0.0, std=0.02)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        module.bias.data.zero_()\n",
    "        module.weight.data.fill_(1.0)\n",
    "    if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "        module.bias.data.zero_()\n",
    "\n",
    "# 모델의 모든 가중치 초기화\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 파라미터 정의\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "    losses = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for batch in tqdm(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, losses / n_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:33<00:00,  5.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.11701876103881924 accuracy 0.888268156424581\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:32<00:00,  5.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.4098627818839406 accuracy 0.4776536312849162\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 179/179 [00:33<00:00,  5.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.3524361500443693 accuracy 0.5363128491620112\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1}/{epochs}')\n",
    "    print('-' * 10)\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        None,\n",
    "        len(dataset)\n",
    "    )\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./model/save/model_v4.pth\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장 경로 설정\n",
    "def get_model_save_path(base_path, base_filename, ext):\n",
    "    version = 1\n",
    "    while True:\n",
    "        model_save_path = f\"{base_path}/{base_filename}_v{version}{ext}\"\n",
    "        if not os.path.exists(model_save_path):\n",
    "            return model_save_path\n",
    "        version += 1\n",
    "\n",
    "# 모델 저장\n",
    "base_path = './model/save'\n",
    "base_filename = 'model'\n",
    "ext = '.pth'\n",
    "\n",
    "model_save_path = get_model_save_path(base_path, base_filename, ext)\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Model saved to {model_save_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>파이썬에서 리스트와 튜플의 차이는 무엇인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>파이썬에서 딕셔너리를 어떻게 정의하나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>파이썬에서 클래스는 어떻게 생성하나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>파이썬에서 파일을 읽고 쓰는 방법은 무엇인가요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>파이썬의 주요 내장 함수들은 무엇이 있나요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     question\n",
       "0   파이썬에서 리스트와 튜플의 차이는 무엇인가요?\n",
       "1      파이썬에서 딕셔너리를 어떻게 정의하나요?\n",
       "2       파이썬에서 클래스는 어떻게 생성하나요?\n",
       "3  파이썬에서 파일을 읽고 쓰는 방법은 무엇인가요?\n",
       "4    파이썬의 주요 내장 함수들은 무엇이 있나요?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df = pd.read_excel('./model/data/valid_set.xlsx')\n",
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증할 데이터 정의\n",
    "class QuestionDataset(Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# 모델 불러오기\n",
    "model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1', num_labels=2)  # 모델의 아키텍처 설정\n",
    "model_save_path = './model/save/model_v1.pth'  # 가중치 불러오기\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "# 검증할 데이터 준비\n",
    "validation_texts = validation_df['question'].tolist()\n",
    "\n",
    "max_len = 128\n",
    "batch_size = 2\n",
    "\n",
    "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
    "validation_dataset = QuestionDataset(validation_texts, tokenizer, max_len)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 예측 함수 정의\n",
    "def predict(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "\n",
    "            logits = outputs.logits\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 75/75 [00:02<00:00, 25.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장: 파이썬에서 리스트와 튜플의 차이는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 딕셔너리를 어떻게 정의하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 클래스는 어떻게 생성하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 파일을 읽고 쓰는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 주요 내장 함수들은 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 for 루프의 기본 구조는 어떻게 되나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 예외 처리는 어떻게 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 패키지를 설치하는 명령어는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 주요 데이터 타입에는 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 함수는 어떻게 정의하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트의 요소를 정렬하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 문자열 포매팅은 어떻게 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 lambda 함수는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 모듈과 패키지의 차이는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 글로벌 변수와 로컬 변수의 차이는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 주요 표준 라이브러리에는 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 set 자료형은 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 map 함수는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 데코레이터는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 제너레이터는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트 컴프리헨션은 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 가비지 컬렉션은 어떻게 동작하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 멀티스레딩을 구현하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 데이터베이스 연결은 어떻게 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 JSON 데이터를 처리하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 최근에 본 영화 중 가장 인상 깊었던 것은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 좋아하는 계절은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 아침에 주로 먹는 음식은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 최근에 간 여행지는 어디인가요? -> 예측된 레이블: yes\n",
      "문장: 주말에 주로 하는 활동은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 좋아하는 음악 장르는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 최근에 읽은 책은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 좋아하는 스포츠는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 친구들과 자주 가는 장소는 어디인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 좋아하는 색은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 좋아하는 음료는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 좋아하는 음식은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 최근에 본 드라마는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 취미가 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 좋아하는 꽃은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 최근에 본 연극이나 뮤지컬은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 애완동물이 있나요? -> 예측된 레이블: yes\n",
      "문장: 가장 좋아하는 과일은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 집에서 가장 좋아하는 공간은 어디인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 기억에 남는 생일 선물은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 좋아하는 커피 종류는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 최근에 본 예능 프로그램은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 주말에 가장 자주 가는 장소는 어디인가요? -> 예측된 레이블: yes\n",
      "문장: 가장 좋아하는 운동 선수는 누구인가요? -> 예측된 레이블: yes\n",
      "문장: 최근에 본 뉴스 중 가장 기억에 남는 것은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬이 인터프리터 언어인 이유는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 주요 특징은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 GIL(Global Interpreter Lock)은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 동적 타이핑(dynamic typing)이란 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 주요 데이터 타입은 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 강한 타입 강제(strong typing)란 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 인터프리터를 실행하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬 스크립트를 실행하는 명령어는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 PEP 8은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 주석은 어떻게 작성하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 변수를 선언하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬 변수의 명명 규칙은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 변수의 타입을 확인하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 여러 변수를 한 줄에 선언하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 변수를 삭제하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 변수에 값을 할당하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 상수를 정의하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 전역 변수와 지역 변수의 차이는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 변수 범위(scope)에 대해 설명해주세요. -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 변수 값을 교환하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 print() 함수는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 len() 함수는 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 type() 함수는 무엇을 반환하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 input() 함수는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 int() 함수는 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 str() 함수는 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 list() 함수는 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 dict() 함수는 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 sum() 함수는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 range() 함수는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 패키지를 설치하는 명령어는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 os 패키지는 무엇을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 sys 패키지는 무엇을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 math 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 random 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 datetime 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 time 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 json 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 re 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬의 collections 패키지는 어떤 기능을 제공하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 개행 문자는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 이스케이프 문자는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\n의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\t의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\\\의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\'의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\\"의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\b의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\r의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 \\f의 역할은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 for 루프의 기본 구조는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 while 루프의 기본 구조는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 break 문은 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 continue 문은 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 else 문은 반복문과 어떻게 사용되나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 for 루프와 함께 사용하는 함수에는 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 중첩 반복문은 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 반복문을 사용하여 리스트를 순회하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 range() 함수를 사용한 반복문 예제는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 무한 루프를 만드는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 if 문의 기본 구조는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 elif 문은 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 else 문은 어떤 역할을 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 중첩 조건문은 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 조건문과 논리 연산자의 사용 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 삼항 연산자(ternary operator)는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 조건문과 비교 연산자의 사용 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 조건문과 함께 사용하는 기본 함수에는 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 if-else 문의 예제는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 조건문을 사용한 리스트 필터링 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 튜플을 생성하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트를 생성하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 셋을 생성하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트와 튜플의 차이점은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 튜플과 셋의 차이점은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트의 요소를 추가하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 튜플의 요소를 변경할 수 없는 이유는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 셋의 요소를 제거하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트의 요소를 정렬하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 셋의 중복 요소를 제거하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 문자열을 포맷팅하는 방법에는 무엇이 있나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 f-string을 사용하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 format() 메소드를 사용하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 % 연산자를 사용한 문자열 포맷팅 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 다중 라인 문자열을 포맷팅하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 문자열 포맷팅과 변수 삽입의 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 숫자 포맷팅의 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 날짜와 시간을 포맷팅하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 문자열 포맷팅과 정렬의 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 문자열 포맷팅과 소수점 제어의 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 리스트 컴프리헨션은 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 딕셔너리 컴프리헨션의 예시는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 함수의 기본 구조는 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 람다 함수는 어떻게 사용하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 클래스와 객체의 차이점은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 상속의 기본 개념은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 모듈을 임포트하는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 예외 처리는 어떻게 하나요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 파일을 읽고 쓰는 방법은 무엇인가요? -> 예측된 레이블: yes\n",
      "문장: 파이썬에서 with 문을 사용하는 이유는 무엇인가요? -> 예측된 레이블: yes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 모델 로드 및 가중치 초기화 (이미 초기화된 모델 사용)\n",
    "model = BertForSequenceClassification.from_pretrained('skt/kobert-base-v1', num_labels=2)\n",
    "model.apply(initialize_weights)\n",
    "model = model.to(device)\n",
    "\n",
    "# 예측 수행\n",
    "predictions = predict(model, validation_loader, device)\n",
    "\n",
    "# 결과 출력\n",
    "for text, pred in zip(validation_texts, predictions):\n",
    "    label = \"yes\" if pred == 1 else \"no\"\n",
    "    print(f\"문장: {text} -> 예측된 레이블: {label}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
